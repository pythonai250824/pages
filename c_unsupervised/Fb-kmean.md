# Optimal K Value
  
Χ‘Χ©ΧΧ‘ Χ”Χ–Χ” ΧΧ Χ—Χ Χ• Χ¨Χ•Χ¦Χ™Χ ΧΧ‘Χ—Χ•Χ¨ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ Χ”ΧΧ•Χ‘ Χ‘Χ™Χ•ΧΧ¨ ΧΧΧ•Χ“Χ Χ©ΧΧ Χ•  
ΧΆΧ“ ΧΆΧ›Χ©Χ™Χ• Χ‘Χ—Χ¨Χ Χ• ΧΧ Χ”ΧΧ΅Χ¤Χ¨ Χ§Χ™Χ™ Χ‘Χ¦Χ•Χ¨Χ” ΧΧ§Χ¨ΧΧ™Χ, ΧΧ‘Χ ΧΆΧ›Χ©Χ™Χ• Χ Χ Χ΅Χ” ΧΧ‘Χ—Χ•Χ¨ ΧΧ•ΧΧ• Χ‘Χ¦Χ•Χ¨Χ” Χ—Χ›ΧΧ”  
Χ‘Χ©Χ•Χ Χ” ΧΧΧΧ™Χ“Χ” ΧΆΧ ΧΧ•Χ¨Χ”, Χ›ΧΧ ΧΧ™Χ ΧΧ Χ• ΧΧ©Χ•Χ‘Χ” Χ Χ›Χ•Χ Χ” ΧΧ”Χ©Χ•Χ•Χ ΧΧΧ™Χ” β€“ ΧΧ– ΧΧ™ ΧΧ¤Χ©Χ¨ ΧΧ—Χ©Χ‘ Χ“Χ™Χ•Χ§ Χ¨Χ’Χ™Χ  
ΧΧ›Χ Χ Χ©ΧΧΧ© Χ‘ΧΧ“Χ“ Χ¤Χ Χ™ΧΧ™ Χ©ΧΧ•Χ“Χ“ ΧΆΧ“ Χ›ΧΧ” Χ”Χ Χ§Χ•Χ“Χ•Χ Χ§Χ¨Χ•Χ‘Χ•Χ ΧΧΧ¨Χ›Χ– Χ”Χ§Χ‘Χ•Χ¦Χ” Χ©ΧΧ”Χ
  
### Sum of Squared Distances (SSD)
  
**Χ΅Χ›Χ•Χ Χ¨Χ™Χ‘Χ•ΧΆΧ™ Χ”ΧΧ¨Χ—Χ§Χ™Χ** Χ”Χ•Χ ΧΧ“Χ“ Χ¤Χ Χ™ΧΧ™ Χ©ΧΧ©ΧΧ© ΧΧ•ΧΧ Χ• ΧΧ‘Χ“Χ•Χ§ ΧΆΧ“ Χ›ΧΧ” Χ”Χ§Χ‘Χ•Χ¦Χ•Χ Χ©Χ™Χ¦Χ¨Χ Χ• ΧΧ•Χ‘Χ•Χ  
Χ‘Χ›Χ Χ§Χ‘Χ•Χ¦Χ” ΧΧ Χ—Χ Χ• ΧΧ—Χ©Χ‘Χ™Χ ΧΧ Χ”ΧΧ¨Χ—Χ§ Χ©Χ Χ›Χ Χ Χ§Χ•Χ“Χ Χ“ΧΧΧ” ΧΧ”ΧΧ¨Χ›Χ– Χ©Χ Χ”Χ§Χ‘Χ•Χ¦Χ” Χ©ΧΧ” β€“ Χ•ΧΧ– ΧΧΆΧΧ™Χ ΧΧ Χ”ΧΧ¨Χ—Χ§ Χ”Χ–Χ” Χ‘Χ¨Χ™Χ‘Χ•ΧΆ  
ΧΆΧ•Χ©Χ™Χ ΧΧ Χ–Χ” ΧΧ›Χ Χ”Χ Χ§Χ•Χ“Χ•Χ Χ‘Χ›Χ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ β€“ Χ•Χ‘Χ΅Χ•Χ£ ΧΧ—Χ‘Χ¨Χ™Χ ΧΧ Χ›Χ Χ”ΧΆΧ¨Χ›Χ™Χ Χ”ΧΧΧ”  
Χ›Χ›Χ Χ©Χ”Χ΅Χ›Χ•Χ Χ”Χ–Χ” Χ§ΧΧ Χ™Χ•ΧΧ¨ β€“ Χ΅Χ™ΧΧ Χ©Χ”Χ Χ§Χ•Χ“Χ•Χ Χ§Χ¨Χ•Χ‘Χ•Χ Χ™Χ•ΧΧ¨ ΧΧΧ¨Χ›Χ–Χ™Χ, Χ›ΧΧ•ΧΧ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ **ΧΧ”Χ•Χ“Χ§Χ•Χ** Χ•ΧΧ•Χ‘Χ•Χ
  
π“ **ΧΧΧ” ΧΧΆΧΧ™Χ Χ‘Χ¨Χ™Χ‘Χ•ΧΆ?**  
Χ›Χ“Χ™ ΧΧ”ΧΆΧ Χ™Χ© ΧΧ¨Χ—Χ§Χ™Χ Χ’Χ“Χ•ΧΧ™Χ Χ™Χ•ΧΧ¨ β€“ ΧΧ Χ™Χ© Χ Χ§Χ•Χ“Χ” Χ©Χ—Χ¨Χ’Χ” ΧΧΧ•Χ“, Χ”Χ™Χ ΧΧ©Χ¤Χ™ΧΆ Χ”Χ¨Χ‘Χ” Χ™Χ•ΧΧ¨ ΧΆΧ Χ”ΧΧ“Χ“
  
π“ **ΧΧΧ™ ΧΧ©ΧΧΧ©Χ™Χ Χ‘Χ–Χ”?**  
Χ›ΧΧ©Χ¨ ΧΧ™Χ ΧΧ Χ• ΧΧ©Χ•Χ‘Χ•Χ Χ Χ›Χ•Χ Χ•Χ ΧΧ”Χ©Χ•Χ•Χ ΧΧΧ™Χ”Χ, Χ›ΧΧ• Χ‘ΧΧΧ™Χ“Χ” ΧΧ ΧΧ•Χ Χ—Χ™Χ β€“ Χ–Χ• Χ”Χ“Χ¨Χ ΧΧ‘Χ“Χ•Χ§ ΧΧ Χ”ΧΧ•Χ“Χ Χ©ΧΧ Χ• ΧΧΧ¤Χ§Χ“ ΧΧ•Χ‘
  
π“ **Χ“Χ•Χ’ΧΧ” Χ¤Χ©Χ•ΧΧ”:**  
ΧΧ Χ™Χ© Χ§Χ‘Χ•Χ¦Χ” Χ©Χ 5 Χ Χ§Χ•Χ“Χ•Χ Χ©Χ›Χ•ΧΧ Χ§Χ¨Χ•Χ‘Χ•Χ ΧΧΧ¨Χ›Χ– β€“ ΧΧ– Χ”Χ΅Χ›Χ•Χ Χ™Χ”Χ™Χ” Χ ΧΧ•Χ  
ΧΧ Χ‘Χ§Χ‘Χ•Χ¦Χ” ΧΧ—Χ¨Χ Χ”Χ Χ§Χ•Χ“Χ•Χ ΧΧ¤Χ•Χ–Χ¨Χ•Χ β€“ Χ”Χ΅Χ›Χ•Χ Χ™Χ”Χ™Χ” Χ’Χ‘Χ•Χ” Χ™Χ•ΧΧ¨, Χ•Χ”ΧΧ—Χ©Χ‘ Χ™Χ‘Χ™Χ Χ©Χ”Χ§Χ‘Χ•Χ¦Χ” Χ”Χ–Χ• Χ¤Χ—Χ•Χ ΧΧ•Χ‘Χ”
   
---
  
# Variation Within Cluster
  
Χ›Χ“Χ™ ΧΧΧ“Χ•Χ“ ΧΧ ΧΧ™Χ›Χ•Χ Χ”Χ—ΧΧ•Χ§Χ” ΧΧ Χ—Χ Χ• ΧΧ©ΧΧΧ©Χ™Χ Χ‘ΧΧ¨Χ—Χ§ Χ”Χ›Χ•ΧΧ Χ©Χ Χ›Χ Χ Χ§Χ•Χ“Χ” ΧΧ”ΧΧ¨Χ›Χ– Χ©Χ Χ”Χ§Χ‘Χ•Χ¦Χ” Χ©ΧΧ”  
ΧΧ Χ›Χ Χ”Χ Χ§Χ•Χ“Χ•Χ Χ§Χ¨Χ•Χ‘Χ•Χ ΧΧΧ•Χ“ ΧΧΧ¨Χ›Χ– β€“ Χ΅Χ™ΧΧ Χ©Χ”Χ—ΧΧ•Χ§Χ” ΧΧ•Χ‘Χ”  
Χ›Χ›Χ Χ©Χ”Χ§Χ‘Χ•Χ¦Χ•Χ ΧΧ”Χ•Χ“Χ§Χ•Χ β€“ Χ›ΧΧ•ΧΧ¨ Χ›Χ Χ Χ§Χ•Χ“Χ” Χ§Χ¨Χ•Χ‘Χ” ΧΧΧ•Χ“ ΧΧ¦Χ ΧΧ¨Χ•ΧΧ™Χ“ β€“ Χ›Χ›Χ” Χ”ΧΧ•Χ“Χ ΧΧ•Χ‘ Χ™Χ•ΧΧ¨  
Χ›Χ“Χ™ ΧΧΧ“Χ•Χ“ ΧΧ Χ–Χ”, ΧΧ—Χ©Χ‘Χ™Χ ΧΧ Χ”ΧΧ¨Χ—Χ§ Χ©Χ Χ›Χ Χ Χ§Χ•Χ“Χ” ΧΧ”ΧΧ¨Χ›Χ–, ΧΧΆΧΧ™Χ Χ‘Χ¨Χ™Χ‘Χ•ΧΆ, Χ•ΧΧ—Χ‘Χ¨Χ™Χ ΧΧ Χ›Χ Χ”ΧΧ•Χ¦ΧΧ•Χ  
Χ”ΧΧΧ¨Χ” Χ©ΧΧ Χ• Χ”Χ™Χ ΧΧ”Χ§ΧΧ™Χ ΧΧ Χ”ΧΆΧ¨Χ Χ”Χ–Χ” Χ›ΧΧ” Χ©Χ™Χ•ΧΧ¨
  
---
  
# Increasing K
  
ΧΧ Χ ΧΧ©Χ™Χ ΧΧ”Χ’Χ“Χ™Χ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ β€“ Χ”ΧΆΧ¨Χ Χ©ΧΧ Χ—Χ Χ• ΧΧ•Χ“Χ“Χ™Χ Χ™ΧΧ Χ•Χ™Χ™Χ¨Χ“  
ΧΧΧ”? Χ›Χ™ Χ›Χ Χ Χ§Χ•Χ“Χ” ΧΧ•Χ›Χ ΧΧ”Χ™Χ•Χ Χ§Χ¨Χ•Χ‘Χ” Χ™Χ•ΧΧ¨ ΧΧ¦Χ ΧΧ¨Χ•ΧΧ™Χ“  
ΧΧ Χ Χ’Χ“Χ™Χ ΧΧ Χ§Χ™Χ™ ΧΧΧ΅Χ¤Χ¨ ΧΧΧ•Χ“ Χ’Χ“Χ•Χ, ΧΧ¤Χ™ΧΧ• Χ›Χ–Χ” Χ©Χ›Χ Χ Χ§Χ•Χ“Χ” ΧΧ§Χ‘Χ Χ§Χ‘Χ•Χ¦Χ” ΧΧ©ΧΧ” β€“ ΧΧ– Χ”ΧΧ¨Χ—Χ§Χ™Χ Χ™Χ”Χ™Χ• ΧΧ¤Χ΅  
ΧΧ‘Χ Χ–Χ” ΧΧ ΧΧ•Χ‘ β€“ Χ›Χ™ ΧΧ– ΧΧ Χ—Χ Χ• Χ¤Χ©Χ•Χ ΧΧΧΧ™ΧΧ™Χ ΧΧ ΧΆΧ¦ΧΧ Χ• Χ‘Χ“Χ™Χ•Χ§ ΧΧ ΧΧ•Χ Χ™Χ Χ”Χ§Χ™Χ™ΧΧ™Χ β€“ Χ•Χ–Χ” Χ Χ§Χ¨Χ **ΧΧΧ™Χ“Χ Χ™ΧΧ¨**  
Χ”ΧΧ•Χ“Χ Χ”Χ–Χ” Χ™Χ™Χ›Χ©Χ ΧΆΧ Χ“ΧΧΧ” Χ—Χ“Χ©
  
<img src="images/kmean6.png" style="width: 100%" />
  
-
<img src="images/kmean7.png" style="width: 100%" />
  
---
  
# Elbow Method
  
Χ›Χ“Χ™ ΧΧΧ¦Χ•Χ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ Χ”Χ›Χ™ ΧΧΧΧ™Χ β€“ ΧΧ Χ—Χ Χ• ΧΧ©ΧΧΧ©Χ™Χ Χ‘Χ©Χ™ΧΧ” Χ©Χ Χ§Χ¨ΧΧ **Χ©Χ™ΧΧ Χ”ΧΧ¨Χ¤Χ§**  
Χ‘Χ•Χ Χ™Χ Χ’Χ¨Χ£ Χ©Χ‘Χ• ΧΆΧ Χ¦Χ™Χ¨ X Χ©ΧΧ™Χ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ, Χ•ΧΆΧ Χ¦Χ™Χ¨ Y ΧΧ ΧΧ“Χ“ Χ”ΧΧ¨Χ—Χ§Χ™Χ  
ΧΧ—Χ¤Χ©Χ™Χ ΧΧ Χ”Χ Χ§Χ•Χ“Χ” Χ©Χ‘Χ” Χ”Χ©Χ™Χ¤Χ•Χ¨ ΧΧ¤Χ΅Χ™Χ§ ΧΧ”Χ™Χ•Χ ΧΧ©ΧΧΆΧ•ΧΧ™ β€“ Χ©Χ Χ–Χ” Χ Χ¨ΧΧ” Χ›ΧΧ• "ΧΧ¨Χ¤Χ§"  
ΧΧ©Χ Χ•Χ”ΧΧΧ”, Χ›Χ ΧΧ•Χ΅Χ¤Χ Χ§Χ‘Χ•Χ¦Χ” ΧΧ ΧΧ•Χ΅Χ™Χ¤Χ” Χ”Χ¨Χ‘Χ” ΧΧΧ™Χ›Χ•Χ Χ”ΧΧ•Χ“Χ β€“ ΧΧ– ΧΆΧ•Χ¦Χ¨Χ™Χ Χ©Χ
  
<img src="images/kmean8.png" style="width: 80%" />
  
### WCSS - Within-Cluster Sum of Squares
  
Χ–Χ”Χ• Χ©Χ Χ Χ•Χ΅Χ£ ΧΧΧ•Χ©Χ’ Χ©ΧΧ Χ—Χ Χ• Χ›Χ‘Χ¨ ΧΧ›Χ™Χ¨Χ™Χ Χ‘Χ©Χ **Χ΅Χ›Χ•Χ Χ¨Χ™Χ‘Χ•ΧΆΧ™ Χ”ΧΧ¨Χ—Χ§Χ™Χ**  
Χ›ΧΧ•ΧΧ¨: Χ‘Χ›Χ Χ§Χ‘Χ•Χ¦Χ”, ΧΧ—Χ©Χ‘Χ™Χ ΧΧ Χ”ΧΧ¨Χ—Χ§ Χ©Χ Χ›Χ Χ Χ§Χ•Χ“Χ” ΧΧ”ΧΧ¨Χ›Χ– Χ©Χ Χ”Χ§Χ‘Χ•Χ¦Χ” Χ©ΧΧ”, ΧΧΆΧΧ™Χ Χ‘Χ¨Χ™Χ‘Χ•ΧΆ β€“ Χ•ΧΧ– ΧΧ—Χ‘Χ¨Χ™Χ ΧΧ Χ›Χ Χ–Χ”  
ΧΆΧ•Χ©Χ™Χ ΧΧ Χ–Χ” Χ‘Χ›Χ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ, Χ•ΧΧ—Χ‘Χ¨Χ™Χ Χ‘Χ™Χ Χ›Χ•ΧΧ  
Χ–Χ” Χ Χ•ΧΧ ΧΧ Χ• ΧΧ“Χ“ Χ›ΧΧΧ™ Χ©Χ Χ›ΧΧ” **Χ”Χ Χ§Χ•Χ“Χ•Χ Χ‘Χ›Χ Χ§ΧΧΧ΅ΧΧ¨ Χ§Χ¨Χ•Χ‘Χ•Χ ΧΧΧ¨Χ›Χ– Χ©ΧΧ”Χ**
  
π“ **ΧΧΧ” Χ–Χ” Χ—Χ©Χ•Χ‘?**  
ΧΧ Χ—Χ Χ• Χ¨Χ•Χ¦Χ™Χ Χ©Χ”ΧΧ¨Χ—Χ§Χ™Χ Χ‘ΧΧ•Χ Χ›Χ Χ§Χ‘Χ•Χ¦Χ” Χ™Χ”Χ™Χ• Χ›ΧΧ” Χ©Χ™Χ•ΧΧ¨ Χ§ΧΧ Χ™Χ  
Χ›Χ›Χ” Χ Χ“ΧΆ Χ©Χ”Χ§ΧΧΧ΅ΧΧ¨Χ™Χ ΧΧ•Χ‘Χ™Χ Χ•Χ”ΧΧ•Χ“Χ ΧΧ•Χ¦ΧΧ—
  
π“ **ΧΧΧ™ ΧΧ©ΧΧΧ©Χ™Χ Χ‘Χ–Χ”?**  
Χ›Χ©Χ¨Χ•Χ¦Χ™Χ ΧΧ‘Χ—Χ•Χ¨ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ Χ”ΧΧ™Χ“Χ™ΧΧΧ™ Χ‘Χ©Χ™ΧΧ **Χ”ΧΧ¨Χ¤Χ§**
  
π“‰ **Χ”ΧΆΧ¨Χ Χ”Χ–Χ” ΧΧΧ™Χ“ Χ™Χ•Χ¨Χ“ Χ›Χ›Χ Χ©ΧΧΆΧΧ™Χ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ**  
ΧΧ‘Χ Χ‘Χ©ΧΧ‘ ΧΧ΅Χ•Χ™Χ Χ”Χ™Χ¨Χ™Χ“Χ” ΧΧ¤Χ΅Χ™Χ§Χ” ΧΧ”Χ™Χ•Χ ΧΧ©ΧΧΆΧ•ΧΧ™Χ β€“ Χ•Χ©Χ Χ ΧΧ¦Χ "Χ”ΧΧ¨Χ¤Χ§", Χ©Χ–Χ” ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ•Χ Χ”Χ›Χ™ ΧΧ•Χ‘
  
Χ‘Χ Χ§Χ•Χ“Χ” K = 4 Χ¨Χ•ΧΧ™Χ Χ©Χ”Χ™Χ¨Χ™Χ“Χ” Χ ΧΆΧ¦Χ¨Χ β€“ Χ•ΧΧ›Χ Χ–Χ” Χ›Χ Χ¨ΧΧ” Χ”ΧΧ΅Χ¤Χ¨ Χ”ΧΧ•Χ¤ΧΧ™ΧΧΧ™ ΧΧ§ΧΧΧ΅ΧΧ¨Χ™Χ
  
---
  
# Elbow Method - Python Example
  
## pd.get_dummies
  
Χ”Χ¤Χ§Χ•Χ“Χ” Χ”Χ–Χ• ΧΧ©ΧΧ©Χ Χ›Χ“Χ™ ΧΧ”ΧΧ™Χ¨ ΧΆΧΧ•Χ“Χ•Χ ΧΧ§Χ΅ΧΧ•ΧΧΧ™Χ•Χ ΧΧΆΧΧ•Χ“Χ•Χ ΧΧ΅Χ¤Χ¨Χ™Χ•Χ Χ‘Χ™Χ ΧΧ¨Χ™Χ•Χ  
Χ”Χ™Χ Χ™Χ•Χ¦Χ¨Χ ΧΆΧΧ•Χ“Χ•Χ Χ—Χ“Χ©Χ•Χ, ΧΧ—Χ ΧΧ›Χ ΧΆΧ¨Χ ΧΧ¤Χ©Χ¨Χ™ Χ‘ΧΧ§Χ΅Χ, Χ•ΧΧ΅ΧΧ Χ ΧΆΧ 1 ΧΧ• 0 Χ”ΧΧ Χ”ΧΆΧ¨Χ ΧΧ•Χ¤Χ™ΧΆ
  
### Χ“Χ•Χ’ΧΧ”:
  
ΧΧ Χ‘ΧΆΧΧ•Χ“Χ 'Χ¦Χ‘ΧΆ' Χ™Χ© ΧΧ Χ”ΧΆΧ¨Χ›Χ™Χ:
- ΧΧ“Χ•Χ  
- Χ›Χ—Χ•Χ  
- Χ™Χ¨Χ•Χ§  
  
ΧΧ– ΧΧ—Χ¨Χ™ Χ”Χ¤Χ§Χ•Χ“Χ” Χ Χ§Χ‘Χ Χ©ΧΧ•Χ© ΧΆΧΧ•Χ“Χ•Χ Χ—Χ“Χ©Χ•Χ:
- Χ¦Χ‘ΧΆ_ΧΧ“Χ•Χ  
- Χ¦Χ‘ΧΆ_Χ›Χ—Χ•Χ  
- Χ¦Χ‘ΧΆ_Χ™Χ¨Χ•Χ§  
  
Χ•Χ›Χ Χ©Χ•Χ¨Χ” ΧΧ§Χ‘Χ 1 Χ‘ΧΆΧΧ•Χ“Χ” Χ”ΧΧΧΧ™ΧΧ”, Χ•ΦΎ0 Χ‘Χ©ΧΧ¨
  
### ΧΧΧ” Χ–Χ” Χ—Χ©Χ•Χ‘?
  
ΧΧ•Χ“ΧΧ™Χ Χ©Χ ΧΧΧ™Χ“Χ ΧΧ›Χ•Χ Χ” ΧΧ Χ™Χ•Χ“ΧΆΧ™Χ ΧΧ”ΧΧΧ•Χ“Χ“ ΧΆΧ ΧΧ—Χ¨Χ•Χ–Χ•Χ  
ΧΧ›Χ Χ—Χ™Χ™Χ‘Χ™Χ ΧΧ”Χ¤Χ•Χ ΧΧ Χ”ΧΧ™Χ“ΧΆ Χ”Χ§ΧΧ’Χ•Χ¨Χ™ ΧΧΧ΅Χ¤Χ¨Χ™Χ ΧΧ¤Χ Χ™ Χ©ΧΧ›Χ Χ™Χ΅Χ™Χ ΧΧ•ΧΧ• ΧΧΧ•Χ“Χ  
Χ”ΧΧ¨Χ” Χ›Χ–Χ• Χ Χ§Χ¨ΧΧ **Χ§Χ™Χ“Χ•Χ“ ΧΧ—Χ“ Χ—Χ**, Χ•Χ”Χ™Χ ΧΧΧ¤Χ©Χ¨Χ ΧΧ”Χ¤ΧΆΧ™Χ Χ—Χ™Χ©Χ•Χ‘Χ™Χ ΧΧΧΧΧ™Χ™Χ ΧΆΧ Χ”Χ“ΧΧΧ” One-Hot Encoding
  
π“ ΧΧ™Χ¤: ΧΧΧ—Χ¨ Χ”Χ§Χ™Χ“Χ•Χ“ Χ›Χ“ΧΧ™ ΧΧ‘Χ¦ΧΆ **Χ΅Χ§Χ™Χ™ΧΧ™Χ Χ’** β€“ Χ›Χ“Χ™ Χ©Χ›Χ Χ”ΧΆΧ¨Χ›Χ™Χ Χ™Χ”Χ™Χ• Χ‘ΧΧ•ΧΧ• Χ΅Χ“Χ¨ Χ’Χ•Χ“Χ Χ‘Χ—Χ™Χ©Χ•Χ‘ Χ”ΧΧ¨Χ—Χ§Χ™Χ
  
### Χ“Χ•Χ’ΧΧ” ΧΦΎget_dummies
  
Χ Χ Χ™Χ— Χ©Χ™Χ© ΧΧ Χ• Χ“ΧΧΧ” Χ›Χ–Χ”:
  
| Χ©Χ     | Χ¦Χ‘ΧΆ    | ΧΧ™Χ   |
|--------|--------|--------|
| Χ“Χ Χ™    | ΧΧ“Χ•Χ   | Χ–Χ›Χ¨   |
| ΧΧΧ¨    | Χ›Χ—Χ•Χ   | Χ Χ§Χ‘Χ”  |
| Χ™Χ•Χ΅Χ™   | Χ™Χ¨Χ•Χ§   | Χ–Χ›Χ¨   |
| Χ¨Χ•Χ Χ™   | Χ›Χ—Χ•Χ   | Χ Χ§Χ‘Χ”  |
  
ΧΧ—Χ¨Χ™ Χ”Χ¤ΧΆΧΧ Χ”Χ¤Χ§Χ•Χ“Χ” `get_dummies(df)` Χ Χ§Χ‘Χ:
  
| Χ©Χ     | Χ¦Χ‘ΧΆ_ΧΧ“Χ•Χ | Χ¦Χ‘ΧΆ_Χ›Χ—Χ•Χ | Χ¦Χ‘ΧΆ_Χ™Χ¨Χ•Χ§ | ΧΧ™Χ_Χ Χ§Χ‘Χ” | ΧΧ™Χ_Χ–Χ›Χ¨ |
|--------|-----------|------------|-----------|------------|-----------|
| Χ“Χ Χ™    | 1         | 0          | 0         | 0          | 1         |
| ΧΧΧ¨    | 0         | 1          | 0         | 1          | 0         |
| Χ™Χ•Χ΅Χ™   | 0         | 0          | 1         | 0          | 1         |
| Χ¨Χ•Χ Χ™   | 0         | 1          | 0         | 1          | 0         |
  
π“ Χ”ΧΧ—Χ©Χ‘ ΧΧ Χ¨Χ•ΧΧ” "Χ›Χ—Χ•Χ" ΧΧ• "Χ Χ§Χ‘Χ”" β€“ Χ”Χ•Χ Χ¨Χ•ΧΧ” **0 ΧΧ• 1**  
Χ›Χ ΧΧ¤Χ©Χ¨ ΧΧ—Χ©Χ‘ ΧΧ¨Χ—Χ§Χ™Χ Χ‘Χ™Χ Χ Χ§Χ•Χ“Χ•Χ, Χ›Χ™ Χ”Χ›Χ•Χ ΧΧ‘Χ•Χ΅Χ΅ ΧΧ΅Χ¤Χ¨Χ™Χ
  
  
  
Χ”Χ Χ” Χ“Χ•Χ’ΧΧ” ΧΧ¤Χ™Χ™ΧΧ•Χ Χ©Χ‘Χ” ΧΧ Χ—Χ Χ• ΧΧ—Χ©Χ‘Χ™Χ ΧΧ Χ”Χ’Χ¨Χ£:
  
```python
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
  
df = pd.read_csv("bank-full.csv")
  
# Convert categorical columns to binary using one-hot encoding
df_dummies = pd.get_dummies(df)
  
# Apply feature scaling
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_dummies)
  
# Calculate the sum of squared distances (SSD) for K values from 1 to 10
ssd = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df_scaled)
    ssd.append(kmeans.inertia_)
  
# Elbow method plot
plt.plot(range(1, 11), ssd, marker='o')
plt.xlabel("Number of Clusters (K)")
plt.ylabel("Within-Cluster Sum of Squares (WCSS)")
plt.title("Elbow Method to Determine Optimal K")
plt.grid(True)
plt.show()
```
  
<img src="images/kmean9.png" style="width: 80%" />
  
SSD = 6 is optimal
  
### ΧΆΧ ΧΧ™ΧΧ• Χ¤Χ™Χ¦β€™Χ¨Χ™Χ Χ”ΧΧ•Χ“Χ Χ¨Χ¥?
  
Χ”ΧΧ•Χ“Χ Χ¨Χ¥ ΧΆΧ Χ›Χ Χ”ΧΆΧΧ•Χ“Χ•Χ Χ©Χ‘Χ§Χ•Χ‘Χ¥ β€“ Χ’Χ ΧΧ΅Χ¤Χ¨Χ™Χ•Χ Χ•Χ’Χ ΧΧ§Χ΅ΧΧ•ΧΧΧ™Χ•Χ  
Χ›Χ“Χ™ ΧΧΆΧ‘Χ•Χ“ ΧΆΧ ΧΆΧΧ•Χ“Χ•Χ ΧΧ§Χ΅Χ, ΧΧ‘Χ¦ΧΆΧ™Χ **Χ§Χ™Χ“Χ•Χ“ ΧΧ—Χ“-Χ—Χ** Χ©Χ”Χ•Χ¤Χ Χ›Χ ΧΆΧ¨Χ ΧΧ™ΧΧ•ΧΧ™ ΧΧΆΧΧ•Χ“Χ•Χ Χ©Χ 0 Χ•ΦΎ1  
ΧΧΧ—Χ¨ ΧΧ›Χ ΧΧ‘Χ¦ΧΆΧ™Χ **Χ΅Χ§Χ™Χ™ΧΧ™Χ Χ’** Χ›Χ“Χ™ Χ©Χ”ΧΆΧ¨Χ›Χ™Χ Χ™Χ”Χ™Χ• Χ‘ΧΧ•ΧΧ• Χ΅Χ“Χ¨ Χ’Χ•Χ“Χ  
Χ¨Χ§ ΧΧ– Χ”ΧΧ•Χ“Χ ΧΧ‘Χ¦ΧΆ ΧΧ Χ”Χ—ΧΧ•Χ§Χ” ΧΧ§Χ‘Χ•Χ¦Χ•Χ
  
### ΧΧ” Χ”ΧΧ•Χ“Χ Χ‘ΧΆΧ¦Χ ΧΆΧ•Χ©Χ”?
  
Χ”ΧΧ•Χ“Χ ΧΧ Χ™Χ•Χ“ΧΆ Χ›ΧΧ•Χ ΧΧ¨ΧΧ© β€“ ΧΧ ΧΧ” ΧΧ•Χ‘, ΧΧ ΧΧ” Χ¨ΧΆ  
Χ”Χ•Χ Χ΅Χ•Χ¨Χ§ ΧΧ Χ›Χ Χ”ΧΧ§Χ•Χ—Χ•Χ, ΧΧ©Χ•Χ•Χ” Χ‘Χ™Χ Χ™Χ”Χ ΧΧ¤Χ™ ΧΧΧ¤Χ™Χ™Χ Χ™Χ Χ•ΧΧ—Χ¤Χ© Χ§Χ‘Χ•Χ¦Χ•Χ Χ©Χ ΧΧ§Χ•Χ—Χ•Χ Χ©Χ“Χ•ΧΧ™Χ Χ–Χ” ΧΧ–Χ”  
Χ”ΧΧ•Χ¦ΧΧ” Χ”Χ™Χ Χ—ΧΧ•Χ§Χ” Χ©Χ Χ›Χ Χ”Χ“ΧΧΧ” ΧΧΧ΅Χ¤Χ¨ Χ§Χ‘Χ•Χ¦Χ•Χ Χ©Χ”ΧΧ©ΧΧΧ© Χ”Χ’Χ“Χ™Χ¨ (ΧΧΧ©Χ 6)
  
### ΧΧ” Χ–Χ” ΧΧ•ΧΧ¨ Χ©Χ™Χ© 6 Χ§Χ‘Χ•Χ¦Χ•Χ?
  
Χ–Χ” ΧΧ•ΧΧ¨ Χ©Χ”ΧΧ•Χ“Χ Χ—Χ™ΧΧ§ ΧΧ Χ›Χ Χ”ΧΧ Χ©Χ™Χ Χ‘Χ§Χ•Χ‘Χ¥ ΧΦΎ6 Χ§Χ‘Χ•Χ¦Χ•Χ Χ©Χ•Χ Χ•Χ ΧΆΧ Χ΅ΧΧ Χ”Χ“ΧΧ™Χ•Χ Χ‘Χ™Χ Χ™Χ”Χ  
ΧΧΧ©Χ:
- Χ§Χ‘Χ•Χ¦Χ” ΧΧ—Χ ΧΆΧ©Χ•Χ™Χ” ΧΧ”Χ™Χ•Χ ΧΧ§Χ•Χ—Χ•Χ Χ¦ΧΆΧ™Χ¨Χ™Χ ΧΆΧ ΧΧ©Χ›Χ•Χ¨Χ Χ ΧΧ•Χ›Χ”
- Χ§Χ‘Χ•Χ¦Χ” ΧΧ—Χ¨Χ Χ™Χ›Χ•ΧΧ” ΧΧ”Χ™Χ•Χ ΧΧ§Χ•Χ—Χ•Χ ΧΆΧ Χ¤Χ™Χ§Χ“Χ•Χ Χ•Χ Χ•Χ™Χ¦Χ™Χ‘Χ•Χ ΧΧΆΧ΅Χ•Χ§ΧΧ™Χ
- Χ§Χ‘Χ•Χ¦Χ” Χ©ΧΧ™Χ©Χ™Χ ΧΧ•ΧΧ™ Χ›Χ•ΧΧΧ ΧΧ ΧΧ™ Χ©ΧΆΧ Χ• Χ›Χ ΧΧ§ΧΧ¤Χ™Χ™Χ Χ©Χ™Χ•Χ•Χ§
  
Χ”Χ§Χ‘Χ•Χ¦Χ•Χ Χ”ΧΧΧ” ΧΧ ΧΧ’Χ™ΧΆΧ•Χ ΧΆΧ Χ©ΧΧ•Χ β€“ ΧΧΧ” Χ¦Χ¨Χ™Χ **ΧΧ—Χ§Χ•Χ¨ Χ•ΧΧΧ ΧΧ©ΧΧΆΧ•Χ ΧΧ›Χ Χ§Χ‘Χ•Χ¦Χ”**
  
### ΧΧ” Χ™Χ•Χ¦Χ ΧΧ™ ΧΧ–Χ”?
  
β… Χ¤Χ™ΧΧ•Χ— Χ—Χ›Χ Χ©Χ ΧΧ§Χ•Χ—Χ•Χ  
β… Χ©Χ™Χ•Χ•Χ§ ΧΧ•ΧΧΧ ΧΧ™Χ©Χ™Χ ΧΧ›Χ Χ§Χ‘Χ•Χ¦Χ”  
β… ΧΧ™Χ§Χ•Χ“ Χ‘ΧΧ™Χ¤Χ•Χ Χ‘ΧΧ§Χ•Χ—Χ•Χ ΧΧ΅Χ•Χ›Χ Χ™Χ ΧΧ• Χ™Χ§Χ¨Χ™Χ  
β… Χ”Χ‘Χ Χ” ΧΆΧΧ•Χ§Χ” Χ©Χ ΧΧ‘Χ Χ” Χ”Χ“ΧΧΧ” Χ©ΧΧ
  
### ΧΧ” Χ›Χ“ΧΧ™ ΧΧΆΧ©Χ•Χ ΧΧ—Χ¨Χ™ Χ©ΧΧ§Χ‘ΧΧ™Χ Χ§Χ‘Χ•Χ¦Χ•Χ?
  
- ΧΧ‘Χ“Χ•Χ§ ΧΧΧ¤Χ™Χ™Χ Χ™Χ ΧΆΧ™Χ§Χ¨Χ™Χ™Χ Χ‘Χ›Χ Χ§Χ‘Χ•Χ¦Χ” (ΧΧΧ©Χ Χ’Χ™Χ ΧΧΧ•Χ¦ΧΆ, Χ¨ΧΧ Χ”Χ©Χ›ΧΧ”, ΧΧ’Χ•Χ‘Χ” ΧΧ©Χ™Χ•Χ•Χ§)
- ΧΧΧ Χ©ΧΧ•Χ Χ‘Χ¨Χ•Χ¨Χ™Χ ΧΧ›Χ Χ§Χ‘Χ•Χ¦Χ” β€“ Χ–Χ” Χ”Χ•Χ¤Χ ΧΧ Χ”ΧΧ•Χ“Χ ΧΧ›ΧΧ™ ΧΆΧ΅Χ§Χ™
- ΧΧ”Χ©ΧΧΧ© Χ‘Χ§Χ‘Χ•Χ¦Χ•Χ Χ‘ΧΧ•Χ“ΧΧ™Χ ΧΧ—Χ¨Χ™Χ (Χ›ΧΧ• Χ Χ™Χ‘Χ•Χ™) ΧΧ• Χ‘Χ§Χ‘ΧΧ Χ”Χ—ΧΧΧ•Χ
  
### ΧΧ™Χ Χ™Χ•Χ“ΧΆΧ™Χ ΧΧ” ΧΧΧ¤Χ™Χ™Χ Χ›Χ Χ§Χ‘Χ•Χ¦Χ” ΧΧ—Χ¨Χ™ Χ”Χ—ΧΧ•Χ§Χ”?
  
Χ‘Χ¨Χ’ΧΆ Χ©Χ™Χ© ΧΧ Χ• ΧΧ Χ”ΧΆΧΧ•Χ“Χ” "Χ§ΧΧΧ΅ΧΧ¨" ΧΆΧ ΧΧ΅Χ¤Χ¨ Χ”Χ§Χ‘Χ•Χ¦Χ” Χ©Χ Χ›Χ Χ©Χ•Χ¨Χ” β€“  
ΧΧ Χ—Χ Χ• Χ™Χ›Χ•ΧΧ™Χ ΧΧ‘Χ¦ΧΆ Χ Χ™ΧΧ•Χ— Χ¤Χ©Χ•Χ: ΧΧ—Χ©Χ‘ **ΧΧΧ•Χ¦ΧΆ**, **Χ©Χ›Χ™Χ—** ΧΧ• **ΧΧ—Χ•Χ–Χ™Χ** Χ‘Χ›Χ Χ§Χ‘Χ•Χ¦Χ”
  
### ΧΧ“Χ•Χ’ΧΧ”:
  
- ΧΧ” Χ”Χ’Χ™Χ Χ”ΧΧΧ•Χ¦ΧΆ Χ©Χ Χ›Χ Χ§Χ‘Χ•Χ¦Χ”?  
- ΧΧ™Χ–Χ” Χ΅Χ•Χ’ ΧΆΧ‘Χ•Χ“Χ” Χ”Χ›Χ™ Χ Χ¤Χ•Χ¥ Χ‘Χ›Χ Χ§Χ‘Χ•Χ¦Χ”?  
- ΧΧ” Χ©Χ™ΧΆΧ•Χ¨ Χ”ΧΧ Χ©Χ™Χ Χ©ΧΆΧ Χ• "yes" ΧΧ§ΧΧ¤Χ™Χ™Χ Χ‘Χ›Χ Χ§Χ‘Χ•Χ¦Χ”?
  
Χ›Χ›Χ” ΧΧ–Χ”Χ™Χ ΧΧ‘Χ Χ™Χ•Χ Χ•ΧΧΧ—Χ™ΧΧ™Χ ΧΧ”Χ‘Χ™Χ ΧΧ” ΧΧΧ¤Χ™Χ™Χ Χ›Χ Χ§ΧΧΧ΅ΧΧ¨
  
```python
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
  
# Load the data
df = pd.read_csv("bank-full.csv")
  
# 1. Data preprocessing
# Handle categorical variables
df_encoded = pd.get_dummies(df, drop_first=True)
  
# Scale numerical features
scaler = StandardScaler()
features = df_encoded.columns
df_scaled = pd.DataFrame(scaler.fit_transform(df_encoded), columns=features)
  
# 2. Apply K-means with k=6 (as determined by your elbow method)
k = 6
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
df['cluster'] = kmeans.fit_predict(df_scaled)
  
# 3.1 Size of each cluster
cluster_sizes = df['cluster'].value_counts().sort_index()
print("\nCluster sizes:")
print(cluster_sizes)
print("\nPercentage of total:")
print(round(cluster_sizes / len(df) * 100, 2))
  
# 3.2 Calculate mean values for numerical variables by cluster
numerical_cols = ['age', 'duration', 'campaign', 'pdays', 'previous',
                  'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',
                  'euribor3m', 'nr.employed']
cluster_means = df.groupby('cluster')[numerical_cols].mean()
print("\nNumerical feature means by cluster:")
print(cluster_means)
```
  
Output:
```
  
Cluster sizes:
cluster
0    11622
1     3775
2    11482
3     1498
4    11836
5      975
Name: count, dtype: int64
  
Percentage of total:
cluster
0    28.22
1     9.17
2    27.88
3     3.64
4    28.74
5     2.37
Name: count, dtype: float64
  
Numerical feature means by cluster:
               age    duration  campaign  ...  cons.conf.idx  euribor3m  nr.employed
cluster                                   ...                                       
0        39.940458  251.873516  3.062984  ...     -39.819472   4.962974  5228.097221
1        40.948079  243.476026  1.920265  ...     -41.553272   3.886565  5182.548821
2        39.285752  263.408465  2.125588  ...     -43.366591   1.211547  5079.549747
3        41.857143  321.419893  1.825768  ...     -38.326702   0.985517  5029.139252
4        40.299510  257.087783  2.809902  ...     -38.350566   4.884378  5204.281776
5        39.977436  249.244103  2.572308  ...     -40.317641   3.695877  5169.115385
  
[6 rows x 10 columns]
```
  
### Graphs:
  
#### Amount of each cluster
  
<img src="images/kmeanr1.png" style="width: 70%" />
  
#### Percentage of subscription="yes" for each cluster
  
<img src="images/kmeanr2.png" style="width: 80%" />
  
#### Heatmap of numeric mean for each cluster
  
<img src="images/kmeanr3.png" style="width: 100%" />
  