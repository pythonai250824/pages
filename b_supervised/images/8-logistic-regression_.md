# Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ
  
## Χ”Χ‘ΧΆΧ™Χ” Χ©Χ¨Χ•Χ¦Χ™Χ ΧΧ¤ΧΧ•Χ¨
  
Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ Χ”Χ™Χ Χ©Χ™ΧΧ” Χ΅ΧΧΧ™Χ΅ΧΧ™Χ Χ”ΧΧ©ΧΧ©Χ ΧΧ Χ™Χ‘Χ•Χ™ ΧΧ•Χ¦ΧΧ•Χ Χ‘Χ™Χ ΧΧ¨Χ™Χ•Χ (0 ΧΧ• 1, Χ›Χ ΧΧ• ΧΧ) ΧΆΧ Χ‘Χ΅Χ™Χ΅ ΧΧ©ΧΧ Χ™Χ ΧΧ΅Χ‘Χ™Χ¨Χ™Χ. Χ‘Χ Χ™Χ’Χ•Χ“ ΧΧ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ™Χ ΧΧ¨Χ™Χ Χ©ΧΧ Χ‘ΧΧ ΧΆΧ¨Χ›Χ™Χ Χ¨Χ¦Χ™Χ¤Χ™Χ, Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ ΧΧ—Χ©Χ‘Χ ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©Χ“Χ•Χ’ΧΧ” ΧΧ΅Χ•Χ™ΧΧ ΧΧ©ΧΧ™Χ™Χ ΧΧ§ΧΧ’Χ•Χ¨Χ™Χ” ΧΧ΅Χ•Χ™ΧΧ.
  
**Χ“Χ•Χ’ΧΧ”**: Χ Χ Χ™Χ— Χ©ΧΧ Χ• Χ¨Χ•Χ¦Χ™Χ ΧΧ—Χ–Χ•Χ Χ”ΧΧ ΧΧΧΧ™Χ“ Χ™ΧΆΧ‘Χ•Χ¨ ΧΧ‘Χ—Χ (Χ™Χ¦ΧΧ™Χ—=1, Χ™Χ™Χ›Χ©Χ=0) ΧΆΧ Χ΅ΧΧ ΧΧ΅Χ¤Χ¨ Χ©ΧΆΧ•Χ Χ”ΧΧ™ΧΧ•Χ“ Χ©ΧΧ•. ΧΧ”ΧΧ Χ ΧΧ•Χ Χ™Χ Χ”Χ™Χ΅ΧΧ•Χ¨Χ™Χ™Χ Χ©Χ ΧΧΧΧ™Χ“Χ™Χ:
  
| Χ©ΧΆΧ•Χ ΧΧ™ΧΧ•Χ“ | ΧΧ•Χ¦ΧΧ” (1=ΧΆΧ‘Χ¨, 0=Χ Χ›Χ©Χ) |
|------------|----------------------|
| 1          | 0                    |
| 2          | 0                    |
| 3          | 0                    |
| 4          | 0                    |
| 5          | 1                    |
| 6          | 1                    |
| 7          | 1                    |
| 8          | 1                    |
| 9          | 1                    |
  
ΧΧ Χ• Χ¨Χ•Χ¦Χ™Χ ΧΧΧ¦Χ•Χ ΧΧ•Χ“Χ Χ©Χ™Χ—Χ–Χ” ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©ΧΧΧΧ™Χ“ Χ™ΧΆΧ‘Χ•Χ¨ ΧΧ Χ”ΧΧ‘Χ—Χ Χ‘Χ”ΧΧ‘Χ΅Χ΅ ΧΆΧ Χ©ΧΆΧ•Χ Χ”ΧΧ™ΧΧ•Χ“ Χ©ΧΧ•.
  
## Mathematical Formula and Complete Calculation
  
Logistic regression models the probability that a dependent variable Y equals 1 (in our case, passing the exam) as a function of independent variables X (in our case, study hours). The logistic function (also called the sigmoid function) is used to model this probability:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?P(Y=1|X)%20=%20\frac{1}{1%20+%20e^{-(\beta_0%20+%20\beta_1%20X)}}"/></p>  
  
  
Where:
- <img src="https://latex.codecogs.com/gif.latex?P(Y=1|X)"/> is the probability that Y=1 given X
- <img src="https://latex.codecogs.com/gif.latex?\beta_0"/> is the intercept
- <img src="https://latex.codecogs.com/gif.latex?\beta_1"/> is the coefficient for the independent variable X
- <img src="https://latex.codecogs.com/gif.latex?e"/> is the base of the natural logarithm (approximately 2.71828)
  
The logistic function always outputs a value between 0 and 1, which can be interpreted as a probability.
  
### π“ Χ”Χ΅Χ‘Χ¨ Χ¤Χ©Χ•Χ ΧΆΧ Χ”Χ Χ•Χ΅Χ—Χ”
  
Logistic Regression ΧΧ—Χ©Χ‘Χ Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©ΧΧ©Χ”Χ• Χ™Χ§Χ¨Χ”, ΧΧ¤Χ™ ΧΆΧ¨Χ Χ©Χ ΧΧ©ΧΧ Χ” X (ΧΧΧ©Χ: Χ›ΧΧ” Χ©ΧΆΧ•Χ ΧΧΧ™Χ“Χ”)
  
### Χ”Χ Χ•Χ΅Χ—Χ”:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?P(Y%20=%201%20\mid%20X)%20=%20\frac{1}{1%20+%20e^{-(\beta_0%20+%20\beta_1%20X)}}"/></p>  
  
  
Χ–Χ• Χ Χ§Χ¨ΧΧ **Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ΅Χ™Χ’ΧΧ•ΧΧ™Χ“ (sigmoid function)** β€“ Χ”Χ™Χ ΧΧ—Χ–Χ™Χ¨Χ” ΧΆΧ¨Χ›Χ™Χ Χ‘Χ™Χ 0 ΧΦΎ1, Χ•ΧΧ›Χ ΧΧΧΧ™ΧΧ” ΧΧ—Χ™Χ–Χ•Χ™ Χ”Χ΅ΧΧ‘Χ¨Χ•Χ™Χ•Χ
  
### π§  Χ”Χ΅Χ‘Χ¨Χ™Χ:
  
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?P(Y%20=%201%20\mid%20X)"/></p>  
 β€“
  
   Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©-Y Χ™Χ”Χ™Χ” 1 Χ‘Χ”Χ™Χ ΧΧ X
  
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_0"/></p>  
 β€“ Χ”Χ§Χ‘Χ•ΧΆ (intercept)  
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_1"/></p>  
 β€“ ΧΧ§Χ“Χ Χ©Χ X  
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?e"/></p>  
 β€“ Χ”Χ‘Χ΅Χ™Χ΅ Χ©Χ Χ”ΧΧ•Χ’Χ¨Χ™ΧΧ Χ”ΧΧ‘ΧΆΧ™ (Χ‘ΧΆΧ¨Χ 2.718)
  
### π§® Χ“Χ•Χ’ΧΧ” Χ—Χ™Χ©Χ•Χ‘Χ™Χ:
  
ΧΧ:
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?X%20=%205"/></p>  
 (Χ©ΧΆΧ•Χ ΧΧΧ™Χ“Χ”)
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_0%20=%20-4"/></p>  
  
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_1%20=%201"/></p>  
  
  
ΧΧ–:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?P%20=%20\frac{1}{1%20+%20e^{-(-4%20+%201%20\cdot%205)}}%20=%20\frac{1}{1%20+%20e^{-1}}%20\approx%200.73"/></p>  
  
  
Χ›ΧΧ•ΧΧ¨: Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ ΧΧΆΧ‘Χ•Χ¨ ΧΧ Χ”ΧΧ‘Χ—Χ ΧΧ—Χ¨Χ™ 5 Χ©ΧΆΧ•Χ ΧΧΧ™Χ“Χ” Χ”Χ™Χ Χ‘ΧΆΧ¨Χ **73%** β…
  
### β¨ ΧΧΧ” Logistic Regression Χ©Χ™ΧΧ•Χ©Χ™Χ?
  
- ΧΧ—Χ–Χ™Χ¨Χ” ΧΆΧ¨Χ›Χ™Χ Χ‘Χ™Χ 0 ΧΦΎ1 β†’ ΧΧ•Χ©ΧΧ ΧΧ”Χ΅ΧΧ‘Χ¨Χ•Χ™Χ•Χ
- ΧΧΧ¤Χ©Χ¨Χ ΧΧ”Χ‘Χ™Χ ΧΧ Χ”Χ§Χ©Χ¨ Χ‘Χ™Χ ΧΧ©ΧΧ Χ” Χ¨Χ¦Χ™Χ£ (Χ›ΧΧ• Χ©ΧΆΧ•Χ ΧΧ™ΧΧ•Χ“) ΧΧΧ•Χ¦ΧΧ” Χ‘Χ™Χ ΧΧ¨Χ™Χ (Χ›ΧΧ• Χ”Χ¦ΧΧ—Χ”/Χ›Χ™Χ©ΧΧ•Χ)
  
## Χ“Χ•Χ’ΧΧ Χ¨ΧΧ©Χ•Χ Χ”: Χ Χ™Χ—Χ•Χ© Ξ²β‚€ Χ•ΦΎΞ²β‚
  
### Χ©ΧΧ‘ 1: Χ Χ’Χ“Χ™Χ¨ ΧΧ Χ”Χ‘ΧΆΧ™Χ”
Χ™Χ© ΧΧ Χ• Χ ΧΧ•Χ Χ™Χ (X, Y), Χ›ΧΧ©Χ¨:
- X Χ”Χ•Χ ΧΧ©ΧΧ Χ” Χ¨Χ¦Χ™Χ£ (ΧΧΧ©Χ: Χ©ΧΆΧ•Χ ΧΧΧ™Χ“Χ”)
- Y Χ”Χ•Χ Χ‘Χ™Χ ΧΧ¨Χ™: 0 ΧΧ• 1 (ΧΧΧ©Χ: Χ›Χ™Χ©ΧΧ•Χ ΧΧ• Χ”Χ¦ΧΧ—Χ”)
  
Χ”ΧΧΧ¨Χ” Χ©ΧΧ Χ•:
> ΧΧ—Χ©Χ‘ ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©ΦΎY Χ™Χ”Χ™Χ” 1 Χ‘Χ”Χ™Χ ΧΧ X
  
### Χ©ΧΧ‘ 2: Χ Χ’Χ“Χ™Χ¨ ΧΧ Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” Χ”ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ
  
Χ–Χ• Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” Χ©ΧΧ™ΧΧ” Χ Χ‘Χ Χ” ΧΧ Χ”ΧΧ•Χ“Χ:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?P(Y%20=%201%20\mid%20X)%20=%20\frac{1}{1%20+%20e^{-(\beta_0%20+%20\beta_1%20X)}}"/></p>  
  
  
Χ”Χ™Χ ΧΧΧ™Χ“ ΧΧ—Χ–Χ™Χ¨Χ” ΧΆΧ¨Χ›Χ™Χ Χ‘Χ™Χ 0 ΧΦΎ1 β€“ ΧΧ•Χ©ΧΧ ΧΧ”Χ΅ΧΧ‘Χ¨Χ•Χ™Χ•Χ.
  
### Χ©ΧΧ‘ 3: Χ Χ‘Χ Χ” ΧΧ Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ”Χ›Χ•ΧΧΧ (Likelihood)
  
Χ›Χ“Χ™ ΧΧ‘Χ“Χ•Χ§ ΧΆΧ“ Χ›ΧΧ” Χ”ΧΧ•Χ“Χ Χ©ΧΧ Χ• "ΧΧ“Χ•Χ™Χ§", Χ Χ—Χ©Χ‘ ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©Χ”Χ•Χ Χ—Χ•Χ–Χ” Χ Χ›Χ•Χ ΧΧ Χ›Χ Χ”Χ ΧΧ•Χ Χ™Χ:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L(\beta_0,%20\beta_1)%20=%20\prod_{i=1}^{n}%20\left(%20\hat{p}_i%20\right)^{y_i}%20\cdot%20\left(1%20-%20\hat{p}_i%20\right)^{1%20-%20y_i}"/></p>  
  
  
Χ›ΧΧ©Χ¨:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_i%20=%20\frac{1}{1%20+%20e^{-(\beta_0%20+%20\beta_1%20x_i)}}"/></p>  
  
  
#### β… ΧΧ©ΧΧΆΧ•Χ:
- <img src="https://latex.codecogs.com/gif.latex?\hat{p}_i"/> Χ”Χ™Χ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©Χ Χ”ΧΧ•Χ“Χ ΧΧ›Χ Χ©Χ”ΧΧ¦Χ¤Χ™Χ Χ”-<img src="https://latex.codecogs.com/gif.latex?i"/> ΧΧ”Χ™Χ” 1.
- <img src="https://latex.codecogs.com/gif.latex?y_i"/> Χ”Χ•Χ Χ”ΧΆΧ¨Χ Χ‘Χ¤Χ•ΧΆΧ β€” ΧΧ• 0 ΧΧ• 1.
- Χ›ΧΧ©Χ¨ <img src="https://latex.codecogs.com/gif.latex?y_i%20=%201"/>, ΧΧ§Χ‘ΧΧ™Χ: <img src="https://latex.codecogs.com/gif.latex?\hat{p}_i"/>
- Χ›ΧΧ©Χ¨ <img src="https://latex.codecogs.com/gif.latex?y_i%20=%200"/>, ΧΧ§Χ‘ΧΧ™Χ: <img src="https://latex.codecogs.com/gif.latex?1%20-%20\hat{p}_i"/>
  
Χ”Χ Χ•Χ΅Χ—Χ” Χ—Χ›ΧΧ” Χ‘Χ›Χ Χ©Χ”Χ™Χ ΧΧ©ΧΧΧ©Χ Χ‘-<img src="https://latex.codecogs.com/gif.latex?y_i"/> Χ•-<img src="https://latex.codecogs.com/gif.latex?1%20-%20y_i"/> Χ›Χ“Χ™ ΧΧ›Χ΅Χ•Χ ΧΧ Χ©Χ Χ™ Χ”ΧΧ§Χ¨Χ™Χ Χ‘ΧΧ•ΧΧ” Χ Χ•Χ΅Χ—Χ” β€” Χ‘ΧΧ™ ΧΧ ΧΧ™Χ ΧΧ™Χ•Χ—Χ“Χ™Χ
  
**π― Χ“Χ•Χ’ΧΧ” ΧΧ—Χ™Χ©Χ•Χ‘ Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Likelihood**
  
Χ Χ Χ™Χ— Χ©Χ™Χ© ΧΧ Χ• Χ©ΧΧ™ Χ“Χ•Χ’ΧΧΧ•Χ Χ‘ΧΧ‘Χ“:
  
- Χ“Χ•Χ’ΧΧ” Χ¨ΧΧ©Χ•Χ Χ”: x = 1, y = 1. ΧΧ“Χ•Χ’ΧΧ - ΧΧ—Χ¨Χ™ Χ©ΧΆΧ” Χ©Χ Χ”ΧΧ™Χ›Χ” Χ”Χ™Χ” Χ”Χ™Χ” ΧΆΧ•Χ“Χ£ Χ΅Χ•Χ›Χ¨ Χ‘Χ“Χ
- Χ“Χ•Χ’ΧΧ” Χ©Χ Χ™Χ™Χ”: x = 2, y = 0. ΧΧ“Χ•Χ’ΧΧ - ΧΧ—Χ¨Χ™ Χ©ΧΆΧΧ™Χ™Χ Χ©Χ Χ”ΧΧ™Χ›Χ” ΧΧ Χ”Χ™Χ” ΧΆΧ•Χ“Χ£ Χ΅Χ•Χ›Χ¨ Χ‘Χ“Χ
  
Χ Χ‘Χ—Χ¨ ΧΧ§Χ“ΧΧ™Χ ΧΧΧ•Χ“Χ:
- Ξ²β‚€ = 0  
- Ξ²β‚ = 1
  
**Χ©ΧΧ‘ Χ: Χ Χ—Χ©Χ‘ ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ (p-hat) Χ©Χ”ΧΧ•Χ“Χ Χ—Χ•Χ–Χ”**
  
Χ”Χ Χ•Χ΅Χ—Χ” Χ”Χ™Χ:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_i%20=%20\frac{1}{1%20+%20e^{-(\beta_0%20+%20\beta_1%20x_i)}}"/></p>  
  
  
##### ΧΆΧ‘Χ•Χ¨ Χ”Χ“Χ•Χ’ΧΧ” Χ”Χ¨ΧΧ©Χ•Χ Χ” (x = 1):
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_1%20=%20\frac{1}{1%20+%20e^{-(0%20+%201%20\cdot%201)}}%20=%20\frac{1}{1%20+%20e^{-1}}%20\approx%200.731"/></p>  
  
  
##### ΧΆΧ‘Χ•Χ¨ Χ”Χ“Χ•Χ’ΧΧ” Χ”Χ©Χ Χ™Χ™Χ” (x = 2):
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_2%20=%20\frac{1}{1%20+%20e^{-(0%20+%201%20\cdot%202)}}%20=%20\frac{1}{1%20+%20e^{-2}}%20\approx%200.881"/></p>  
  
  
ΧΧ‘Χ β€“ Χ‘Χ’ΧΧ Χ©ΦΎy = 0 Χ‘ΧΧ§Χ¨Χ” Χ”Χ–Χ”, Χ Χ©ΧΧΧ© Χ‘ΦΎ(1 β’ pΜ‚):
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?1%20-%20\hat{p}_2%20\approx%201%20-%200.881%20=%200.119"/></p>  
  
  
  
**Χ©ΧΧ‘ Χ‘: Χ Χ—Χ©Χ‘ ΧΧ Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”ΦΎLikelihood Χ”Χ›Χ•ΧΧΧ**
  
Χ Χ©ΧΧΧ© Χ‘Χ Χ•Χ΅Χ—Χ”:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L%20=%20(\hat{p}_1)^{y_1}%20\cdot%20(1%20-%20\hat{p}_2)^{1%20-%20y_2}"/></p>  
  
  
Χ Χ¦Χ™Χ‘ ΧΧ Χ”ΧΆΧ¨Χ›Χ™Χ:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L%20=%200.731%20\cdot%200.119%20\approx%200.087"/></p>  
  
  
  
#### π§  ΧΧ” Χ–Χ” ΧΧ•ΧΧ¨?
  
- Χ”ΧΧ•Χ“Χ Χ—Χ–Χ” ΧΧ•Χ‘ Χ™Χ—Χ΅Χ™Χ Χ‘Χ“Χ•Χ’ΧΧ” Χ”Χ¨ΧΧ©Χ•Χ Χ” (73% ΧΆΧ‘Χ•Χ¨ y=1)
- ΧΧ‘Χ ΧΧΆΧ” Χ‘Χ“Χ•Χ’ΧΧ” Χ”Χ©Χ Χ™Χ™Χ” β€” Χ—Χ–Χ” Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ’Χ‘Χ•Χ”Χ” ΧΦΎy=1, ΧΧΧ¨Χ•Χ Χ©Χ”ΧΧ©Χ•Χ‘Χ” Χ”Χ™Χ™ΧΧ” y=0
- ΧΧ›Χ, Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”ΦΎLikelihood Χ”Χ΅Χ•Χ¤Χ™Χ Χ”Χ™Χ Χ‘ΧΆΧ¨Χ 8.7%
  
Χ”ΧΧ΅Χ§Χ Χ”: Χ Χ¨Χ¦Χ” ΧΧΧ¦Χ•Χ Ξ²β‚€ Χ•ΦΎΞ²β‚ ΧΧ—Χ¨Χ™Χ Χ©Χ™Χ™ΧΧ Χ• ΧΆΧ¨Χ Χ’Χ‘Χ•Χ” Χ™Χ•ΧΧ¨ ΧΦΎL.
  
  
## Χ›Χ™Χ¦Χ“ ΧΧΧ¦Χ•Χ ΧΧ Ξ²β‚€ Χ•ΦΎΞ²β‚
  
- ΧΧ—Χ©Χ‘Χ™Χ Χ Χ’Χ–Χ¨Χ•Χ Χ©Χ Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” ΧΧ¤Χ™ Ξ²β‚€ Χ•ΦΎΞ²β‚
- ΧΧ©Χ•Χ•Χ™Χ ΧΦΎ0 Χ›Χ“Χ™ ΧΧΧ¦Χ•Χ Χ Χ§Χ•Χ“Χ Χ§Χ™Χ¦Χ•Χ
- ΧΧ‘Χ... ΧΧ™ ΧΧ¤Χ©Χ¨ ΧΧ¤ΧΧ•Χ¨ ΧΧ Χ–Χ” Χ™Χ“Χ Χ™Χ Χ›ΧΧ• Χ‘Χ¨Χ’Χ¨Χ΅Χ™Χ” Χ¨Χ’Χ™ΧΧ”
  
#### ΧΧ” Χ”ΧΧΧ¨Χ”?
ΧΧ Χ—Χ Χ• Χ¨Χ•Χ¦Χ™Χ ΧΧΧ¦Χ•Χ ΧΧ Χ”ΧΆΧ¨Χ›Χ™Χ Χ©Χ ΧΧ¤Χ™ Ξ²β‚€ Χ•ΦΎΞ²β‚ Χ©ΧΧ‘Χ™ΧΧ™Χ ΧΧ Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”ΧΧ•Χ’ΦΎΧΧ™Χ™Χ§ΧΧ™ ΧΧΧ§Χ΅Χ™ΧΧ•Χ
  
ΧΧ¤Χ™ ΧΧΧΧΧ™Χ§Χ”:
- Χ Χ§Χ•Χ“Χ ΧΧ§Χ΅Χ™ΧΧ•Χ Χ ΧΧ¦ΧΧ Χ›ΧΧ©Χ¨ **Χ”Χ Χ’Χ–Χ¨Χ = 0**
- Χ›ΧΧ•ΧΧ¨: Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” ΧΧ ΧΆΧ•ΧΧ” Χ•ΧΧ Χ™Χ•Χ¨Χ“Χ β€“ Χ–Χ• Χ¤Χ΅Χ’Χ” (ΧΧ• ΧΧ—ΧΧ™Χ, ΧΧ‘Χ Χ›ΧΧ ΧΧ“Χ•Χ‘Χ¨ ΧΆΧ ΧΧ§Χ΅Χ™ΧΧ•Χ)
  
#### ΧΧ”Χ™ Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” Χ©ΧΧ Χ•?
  
Χ–Χ•Χ”Χ™ Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ **Χ”ΧΧ•Χ’ΦΎΧΧ™Χ™Χ§ΧΧ™** (log-likelihood):
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\log%20L(\beta_0,%20\beta_1)%20=%20\sum_{i=1}^{n}%20\left[%20y_i%20\cdot%20\log(\hat{p}_i)%20+%20(1%20-%20y_i)%20\cdot%20\log(1%20-%20\hat{p}_i)%20\right]"/></p>  
  
  
Χ›ΧΧ©Χ¨:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_i%20=%20\frac{1}{1%20+%20e^{-(\beta_0%20+%20\beta_1%20x_i)}}"/></p>  
  
  
#### Χ Χ’Χ–Χ¨Χ•Χ:
  
Χ”Χ Χ’Χ–Χ¨Χ•Χ Χ©Χ Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” ΧΧ¤Χ™ Ξ²β‚€ Χ•ΦΎΞ²β‚ Χ”Χ:
  
- ΧΧ¤Χ™ <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_1"/></p>  
:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\frac{\partial}{\partial%20\beta_1}%20\log%20L%20=%20\sum_{i=1}^{n}%20(y_i%20-%20\hat{p}_i)%20\cdot%20x_i"/></p>  
  
  
- ΧΧ¤Χ™ <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_0"/></p>  
:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\frac{\partial}{\partial%20\beta_0}%20\log%20L%20=%20\sum_{i=1}^{n}%20(y_i%20-%20\hat{p}_i)"/></p>  
  
  
  
#### ΧΧΧ” ΧΧ©Χ•Χ•Χ™Χ ΧΦΎ0?
  
Χ›Χ“Χ™ ΧΧΧ¦Χ•Χ ΧΧ§Χ΅Χ™ΧΧ•Χ, ΧΧ©Χ•Χ•Χ™Χ ΧΧ Χ”Χ Χ’Χ–Χ¨Χ•Χ ΧΦΎ0:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\frac{\partial}{\partial%20\beta}%20\log%20L%20=%200"/></p>  
  
  
ΧΧ‘Χ... ΧΧ Χ Χ™ΧΧ ΧΧ¤ΧΧ•Χ¨ Χ™Χ©Χ™Χ¨Χ•Χ, ΧΧ›Χ Χ ΧΆΧ‘Χ•Χ¨ ΧΧ¤ΧΧ¨Χ•Χ Χ Χ•ΧΧ¨Χ™ (Χ›ΧΧ• Gradient Descent)
  
## π§Έ Χ“Χ•Χ’ΧΧ” ΧΧΧ”ΧΧ™Χ 
  
Χ Χ Χ™Χ— Χ©Χ™Χ© ΧΧ Χ• 2 ΧΧ¦Χ¤Χ™Χ•Χ:
  
| x  | y |
|----|---|
| 1  | 1 |
| 2  | 0 |
  
Χ•Χ Χ Χ™Χ— Χ©Χ›Χ¨Χ’ΧΆ:
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_0%20=%200"/></p>  
  
- <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_1%20=%200"/></p>  
  
  
#### Χ©ΧΧ‘ 1: Χ—Χ™Χ©Χ•Χ‘ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ™Χ•Χ (p-hat)
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_1%20=%20\frac{1}{1%20+%20e^{-(0%20+%200%20\cdot%201)}}%20=%200.5"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\hat{p}_2%20=%20\frac{1}{1%20+%20e^{-(0%20+%200%20\cdot%202)}}%20=%200.5"/></p>  
  
  
#### Χ©ΧΧ‘ 2: 
  
**Χ—Χ™Χ©Χ•Χ‘ Χ Χ’Χ–Χ¨Χ ΧΧ¤Χ™ <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_1"/></p>  
**
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\frac{\partial}{\partial%20\beta_0}%20\log%20L%20=%20\sum_{i=1}^{n}%20(y_i%20-%20\hat{p}_i)"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\sum%20(y_i%20-%20\hat{p}_i)%20\cdot%20x_i%20=(1%20-%200.5)%20\cdot%201%20+%20(0%20-%200.5)%20\cdot%202%20=0.5%20-%201%20=%20-0.5"/></p>  
  
  
ΧΧΧ—Χ¨ Χ•Χ”Χ Χ’Χ–Χ¨Χ Χ©ΧΧ™ΧΧ™Χ, Χ”ΧΧ΅Χ§Χ Χ” Χ”Χ™Χ:
> **Χ¦Χ¨Χ™Χ ΧΧ”Χ’Χ“Χ™Χ ΧΧ** <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_1"/></p>  
 Χ›Χ“Χ™ ΧΧ©Χ¤Χ¨ ΧΧ Χ”ΧΧ•Χ“Χ.
> 
  
**Χ—Χ™Χ©Χ•Χ‘ Χ Χ’Χ–Χ¨Χ ΧΧ¤Χ™ <p align="center"><img src="https://latex.codecogs.com/gif.latex?\beta_0"/></p>  
**
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\frac{\partial}{\partial%20\beta_0}%20\log%20L%20=%20\sum_{i=1}^{n}%20(y_i%20-%20\hat{p}_i)"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\sum%20(y_i%20-%20\hat{p}_i)%20=(1%20-%200.5)%20+%20(0%20-%200.5)%20%20=0.5%20-%200.5%20=%200"/></p>  
  
  
- Χ”Χ Χ’Χ–Χ¨Χ ΧΧ¤Χ™ Ξ²β‚€ Χ©Χ•Χ•Χ” ΧΦΎ0 Χ‘Χ΅Χ™Χ‘Χ•Χ‘ Χ”Χ–Χ”
- ΧΧ›Χ **ΧΧ Χ ΧΆΧ“Χ›Χ ΧΧ Ξ²β‚€** Χ›Χ¨Χ’ΧΆ, Χ›Χ™ ΧΧ™Χ ΧΧΆΧ ΧΧ–Χ•Χ– ΧΧ ΧΧ Χ—Χ Χ• Χ‘Χ“Χ™Χ•Χ§ Χ‘ΧΧΧ¦ΧΆ
  
### π― Χ΅Χ™Χ›Χ•Χ:
- ΧΧ Χ”Χ Χ’Χ–Χ¨Χ Χ—Χ™Χ•Χ‘Χ™Χ β†’ ΧΧΆΧΧ™Χ/ΧΧ•Χ¨Χ™Χ“Χ™Χ ΧΧ Χ”ΧΧ§Χ“Χ ΧΧΧ•Χ™ Χ‘Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”ΧΆΧΧ•Χ (Χ—Χ™Χ•Χ‘Χ™Χ/Χ©ΧΧ™ΧΧ™Χ)
- ΧΧ Χ”Χ Χ’Χ–Χ¨Χ Χ©ΧΧ™ΧΧ™Χ β†’ ΧΧ•Χ¨Χ™Χ“Χ™Χ/ΧΧΆΧΧ™Χ ΧΧ Χ”ΧΧ§Χ“Χ ΧΧΧ•Χ™ Χ‘Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”ΧΆΧΧ•Χ (Χ—Χ™Χ•Χ‘Χ™Χ/Χ©ΧΧ™ΧΧ™Χ)
- Χ ΧΧ©Χ™Χ Χ›Χ ΧΆΧ“ Χ©Χ”Χ Χ’Χ–Χ¨Χ ΧΧ”Χ™Χ” β‰ 0 β€“ Χ•Χ ΧΧ¦Χ ΧΧ ΧΧ§Χ΅Χ™ΧΧ•Χ Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” π’›
  
### ΧΧ©ΧΧΧ©Χ™Χ Χ‘Χ¤ΧΧ¨Χ•Χ Χ Χ•ΧΧ¨Χ™
  
Χ‘Χ’ΧΧ Χ©Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” ΧΧ΅Χ•Χ‘Χ›Χ, Χ”ΧΧ—Χ©Χ‘ Χ¤Χ•ΧΧ¨ ΧΧ•ΧΧ” ΧΆΧ Χ™Χ“Χ™ Χ Χ™Χ΅Χ•Χ™ Χ•ΧΧΆΧ™Χ™Χ” Χ—Χ›ΧΧ”:
  
- Gradient Descent
- Newton-Raphson
- Χ©Χ™ΧΧ•Χ ΧΧ—Χ¨Χ•Χ Χ©Χ ΧΧ¦ΧΧ•Χ Χ‘ΧΧ•Χ“ΧΧ™Χ Χ›ΧΧ• `LogisticRegression` Χ‘Χ΅Χ§Χ™Χ§Χ™ΧΦΎΧΧ¨Χ
  
Χ›Χ Χ¤ΧΆΧ Χ”ΧΧ—Χ©Χ‘ ΧΧ©Χ Χ” Χ§Χ¦Χ ΧΧ Ξ²β‚€ Χ•ΦΎΞ²β‚, Χ‘Χ•Χ“Χ§ ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ™Χ•Χ Χ Χ”Χ™Χ• Χ™Χ•ΧΧ¨ ΧΧ•Χ‘Χ•Χ,  
Χ•ΧΧΧ©Χ™Χ ΧΆΧ“ Χ©Χ”Χ•Χ ΧΧ•Χ¦Χ ΧΧ Χ”ΧΆΧ¨Χ›Χ™Χ Χ”Χ›Χ™ ΧΧ•Χ‘Χ™Χ.
  
### β… Χ΅Χ™Χ›Χ•Χ:
- ΧΧ™Χ Χ Χ•Χ΅Χ—Χ” Χ΅Χ’Χ•Χ¨Χ” ΧΧΧ¦Χ™ΧΧ Ξ²β‚€ Χ•ΦΎΞ²β‚
- Χ”Χ¤ΧΧ¨Χ•Χ ΧΧΧ§Χ‘Χ Χ‘ΧΆΧ–Χ¨Χ ΧΧ•Χ¤ΧΧ™ΧΧ™Χ–Χ¦Χ™Χ” ΧΧΧΧΧ™Χ (Χ Χ•ΧΧ¨Χ™Χ)
- Χ”Χ¤Χ•Χ Χ§Χ¦Χ™Χ” Χ©ΧΧ Χ—Χ Χ• ΧΧΧ§Χ΅ΧΧ™Χ Χ Χ§Χ¨ΧΧ log-likelihood
  
---
  
**ΧΧ¦Χ™ΧΧ Χ”ΧΧ§Χ“ΧΧ™Χ Χ‘Χ¤Χ™Χ™ΧΧ•Χ:**
  
```python
from sklearn.linear_model import LogisticRegression
import numpy as np
  
# Data: Annual income and loan repayment (1=yes, 0=no)
X = np.array([30, 35, 40, 45, 50, 55, 60, 65, 70, 75]).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1])
  
# Fit logistic regression model
model = LogisticRegression(solver='liblinear')
model.fit(X, y)
  
# Get coefficients
b0 = model.intercept_[0]
b1 = model.coef_[0][0]
  
# Print the logistic regression equation
print(f"Logistic regression equation:")
print(f"P(return) = 1 / (1 + e^-({b0:.2f} + {b1:.2f} * income))")
```
output:
```
Logistic regression equation:
P(return) = 1 / (1 + e^-(-0.89 + 0.02 * income))
```
  
  
### Decision Boundary
  
In logistic regression, we often need to make a binary decision based on the predicted probability. The most common threshold is 0.5, meaning:
- If <img src="https://latex.codecogs.com/gif.latex?P(Y=1|X)%20\geq%200.5"/>, we predict Y=1 (pass)
- If <img src="https://latex.codecogs.com/gif.latex?P(Y=1|X)%20&lt;%200.5"/>, we predict Y=0 (fail)
  
Let's find the decision boundary where <img src="https://latex.codecogs.com/gif.latex?P(\text{pass}|\text{hours})%20=%200.5"/>:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?0.5%20=%20\frac{1}{1%20+%20e^{-(-6.7%20+%201.5%20\times%20\text{hours})}}"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?1%20+%20e^{-(-6.7%20+%201.5%20\times%20\text{hours})}%20=%202"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?e^{-(-6.7%20+%201.5%20\times%20\text{hours})}%20=%201"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?-(-6.7%20+%201.5%20\times%20\text{hours})%20=%200"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?-6.7%20+%201.5%20\times%20\text{hours}%20=%200"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?1.5%20\times%20\text{hours}%20=%206.7"/></p>  
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?\text{hours}%20=%20\frac{6.7}{1.5}%20\approx%204.47"/></p>  
  
  
So according to our model, students need to study approximately 4.47 hours to have a 50% chance of passing the exam.
  
## Χ’Χ¨Χ£
  
<img src="log2.png" style="width:80%;"/>
  
Χ”Χ’Χ¨Χ£ ΧΧ¦Χ™Χ’ ΧΧ ΧΆΧ§Χ•ΧΧ Χ”Χ¨Χ’Χ¨Χ΅Χ™Χ” Χ”ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ (Χ”Χ§Χ• Χ”Χ›Χ—Χ•Χ) Χ©ΧΧΧΧ¨ ΧΧ Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ ΧΧΆΧ‘Χ•Χ¨ ΧΧ Χ”ΧΧ‘Χ—Χ Χ›Χ¤Χ•Χ Χ§Χ¦Χ™Χ” Χ©Χ Χ©ΧΆΧ•Χ Χ”ΧΧ™ΧΧ•Χ“. Χ©Χ™ΧΧ• ΧΧ‘ ΧΧ¦Χ•Χ¨Χ” Χ”ΧΧ•Χ¤Χ™Χ™Χ Χ™Χ Χ©Χ ΧΆΧ§Χ•ΧΧ Χ”-S (Χ΅Χ™Χ’ΧΧ•ΧΧ™Χ“) Χ©Χ
Χ”Χ¨Χ’Χ¨Χ΅Χ™Χ” Χ”ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ. Χ”Χ Χ§Χ•Χ“Χ•Χ Χ”ΧΧ“Χ•ΧΧ•Χ Χ”Χ Χ”Χ ΧΧ•Χ Χ™Χ Χ”ΧΧ§Χ•Χ¨Χ™Χ™Χ, Χ•Χ”Χ§Χ• Χ”ΧΧ§Χ•Χ•Χ§Χ• Χ”ΧΧ Χ›Χ™ ΧΧ¦Χ™Χ™Χ ΧΧ Χ”Χ’Χ‘Χ•Χ Χ©Χ‘Χ• Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ ΧΧΆΧ‘Χ•Χ¨ ΧΧ Χ”ΧΧ‘Χ—Χ Χ”Χ™Χ 0.5.
  
## Χ§Χ•Χ“ Χ¤Χ™Χ™ΧΧ•Χ
  
Χ”Χ Χ” Χ§Χ•Χ“ Χ¤Χ™Χ™ΧΧ•Χ ΧΧ™Χ™Χ©Χ•Χ Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ:
  
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
import pandas as pd
from math import log
  
# Our data
hours_studied = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape(-1, 1)  # Study hours
exam_results = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])  # Exam results (0=fail, 1=pass)
  
# Create logistic regression model
model = LogisticRegression(solver='liblinear')
model.fit(hours_studied, exam_results)
  
# Print results
print(f"Intercept (Ξ²β‚€): {model.intercept_[0]:.2f}")
print(f"Coefficient (Ξ²β‚): {model.coef_[0][0]:.2f}")
  
# Calculate equation
equation = f"P(pass) = 1 / (1 + e^-({model.intercept_[0]:.2f} + {model.coef_[0][0]:.2f} Γ— hours))"
print(f"Logistic equation: {equation}")
  
# Helper: get boundary for any probability
def get_threshold(probability):
    logit = log(probability / (1 - probability))
    return (logit - b0) / b1
  
# Coefficients
b0 = model.intercept_[0]
b1 = model.coef_[0][0]
  
# Find decision boundary (probability = 0.5)
decision_boundary = -model.intercept_[0] / model.coef_[0][0]
# or
decision_boundary = get_threshold(0.5)
  
print(f"Decision boundary: {decision_boundary:.2f} hours")
  
# Generate points for the logistic curve
x_test = np.linspace(0, 10, 100).reshape(-1, 1)
y_proba = model.predict_proba(x_test)[:, 1]
  
# Create the graph
plt.figure(figsize=(10, 6))
plt.scatter(hours_studied, exam_results, color='red', marker='o', label='Data points')
plt.plot(x_test, y_proba, color='blue', label='Logistic curve')
plt.axvline(x=decision_boundary, color='green', linestyle='--', label=f'Decision boundary ({decision_boundary:.2f} hours)')
  
# Add labels and formatting
plt.title('Logistic Regression - Study Hours vs. Exam Result')
plt.xlabel('Study Hours')
plt.ylabel('Probability of Passing Exam')
plt.grid(True, alpha=0.3)
plt.legend()
plt.text(1, 0.8, equation, fontsize=10, bbox=dict(facecolor='white', alpha=0.5))
plt.ylim(-0.05, 1.05)
plt.show()
  
# Make predictions for specific study hours
print("\nPredictions:")
for hours in [1, 2, 3, 4, 5, 6]:
    probability = 1 / (1 + np.exp(-(model.intercept_[0] + model.coef_[0][0] * hours)))
    outcome = "Pass" if probability >= 0.5 else "Fail"
    print(f"{hours} hours: {probability:.2f} probability of passing ({outcome})")
```
  
## Χ“Χ•Χ’ΧΧ Χ”Χ¨Χ¦Χ”
  
Χ›ΧΧ©Χ¨ Χ Χ¨Χ™Χ¥ ΧΧ Χ”Χ§Χ•Χ“, Χ Χ§Χ‘Χ:
  
<img src="log1.png" />
  
```
Intercept (Ξ²β‚€): -1.04
Coefficient (Ξ²β‚): 0.38
Logistic equation: P(pass) = 1 / (1 + e^-(-1.04 + 0.38 Γ— hours))
Decision boundary: 2.72 hours
  
Predictions:
1 hours: 0.34 probability of passing (Fail)
2 hours: 0.43 probability of passing (Fail)
3 hours: 0.53 probability of passing (Pass)
4 hours: 0.62 probability of passing (Pass)
5 hours: 0.70 probability of passing (Pass)
6 hours: 0.78 probability of passing (Pass)
```
  
Χ”ΧΧ•Χ¦ΧΧ•Χ ΧΧ¨ΧΧ•Χ Χ©ΧΧΧΧ™Χ“ Χ¦Χ¨Χ™Χ ΧΧΧΧ•Χ“ ΧΧ¤Χ—Χ•Χ 4.43 Χ©ΧΆΧ•Χ Χ›Χ“Χ™ Χ©Χ”Χ΅Χ™Χ›Χ•Χ™ Χ©ΧΧ• ΧΧΆΧ‘Χ•Χ¨ ΧΧ Χ”ΧΧ‘Χ—Χ Χ™Χ”Χ™Χ” ΧΧΆΧ 50%. Χ›ΧΧ• Χ›Χ, ΧΧΧΧ™Χ“ Χ©ΧΧ•ΧΧ“ 6 Χ©ΧΆΧ•Χ Χ™Χ© ΧΧ• Χ΅Χ™Χ›Χ•Χ™ Χ©Χ Χ›-78% ΧΧΆΧ‘Χ•Χ¨ ΧΧ Χ”ΧΧ‘Χ—Χ.
  
## Χ”Χ©Χ•Χ•ΧΧ” Χ‘Χ™Χ Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ™Χ ΧΧ¨Χ™Χ ΧΧ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ
  
| Χ”Χ™Χ‘Χ | Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ™Χ ΧΧ¨Χ™Χ | Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ |
|------|-----------------|------------------|
| **Χ΅Χ•Χ’ ΧΧ©ΧΧ Χ” ΧΧΧ•Χ™** | Χ¨Χ¦Χ™Χ£ (ΧΧ΅Χ¤Χ¨Χ™) | Χ‘Χ™Χ ΧΧ¨Χ™ (0/1, Χ›Χ/ΧΧ) |
| **ΧΧ•Χ•Χ— Χ”ΧΧ—Χ–Χ™Χ** | Χ›Χ ΧΆΧ¨Χ ΧΧΧ©Χ™ <img src="https://latex.codecogs.com/gif.latex?(-\infty,%20\infty)"/> | ΧΆΧ¨Χ Χ‘Χ™Χ 0 Χ-1 (Χ”Χ΅ΧΧ‘Χ¨Χ•Χ) |
| **Χ¤Χ•Χ Χ§Χ¦Χ™Χ™Χ Χ”Χ§Χ™Χ©Χ•Χ¨** | Χ–Χ”Χ•Χ <img src="https://latex.codecogs.com/gif.latex?(y%20=%20\beta_0%20+%20\beta_1%20x)"/> | ΧΧ•Χ’Χ™Χ <img src="https://latex.codecogs.com/gif.latex?(\ln\frac{p}{1-p}%20=%20\beta_0%20+%20\beta_1%20x)"/> |
| **Χ©Χ™ΧΧ ΧΧΧ™Χ“Χ”** | Χ©Χ™ΧΧ Χ”Χ¨Χ™Χ‘Χ•ΧΆΧ™Χ Χ”Χ¤Χ—Χ•ΧΧ™Χ | Χ©Χ™ΧΧ Χ”Χ Χ¨ΧΧ•Χ Χ”ΧΧ§Χ΅Χ™ΧΧΧ™Χ |
| **Χ¤Χ¨Χ©Χ Χ•Χ Χ”ΧΧ§Χ“ΧΧ™Χ** | Χ©Χ™Χ Χ•Χ™ Χ‘-Y ΧΧ™Χ—Χ™Χ“Χ” Χ©Χ X | Χ©Χ™Χ Χ•Χ™ Χ‘ΧΧ•Χ’ Χ©Χ Χ™Χ—Χ΅ Χ”Χ΅Χ™Χ›Χ•Χ™Χ™Χ |
| **Χ¦Χ•Χ¨Χ Χ”Χ§Χ©Χ¨** | Χ§Χ•Χ•Χ™ | ΧΆΧ§Χ•ΧΧ S (Χ΅Χ™Χ’ΧΧ•ΧΧ™Χ“) |
| **Χ”Χ Χ—Χ•Χ** | ΧΧ™Χ Χ™ΧΧ¨Χ™Χ•Χ, Χ Χ•Χ¨ΧΧΧ™Χ•Χ Χ©Χ Χ©ΧΧ¨Χ™Χ•Χ | ΧΧ ΧΧ Χ™Χ—Χ” Χ”ΧΧ¤ΧΧ’Χ•Χ Χ Χ•Χ¨ΧΧΧ™Χ |
  
## Χ™Χ™Χ©Χ•ΧΧ™Χ Χ©Χ Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ
  
Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ ΧΧ©ΧΧ©Χ Χ‘ΧΧ’Χ•Χ•Χ ΧΧ—Χ•ΧΧ™Χ:
  
1. **Χ¨Χ¤Χ•ΧΧ”**: Χ—Χ™Χ–Χ•Χ™ Χ”Χ΅Χ™Χ›Χ•Χ™ ΧΧ”ΧΧ¤ΧΧ—Χ•Χ ΧΧ—ΧΧ” Χ‘Χ”ΧΧ‘Χ΅Χ΅ ΧΆΧ Χ’Χ•Χ¨ΧΧ™ Χ΅Χ™Χ›Χ•Χ
2. **Χ¤Χ™Χ Χ Χ΅Χ™Χ**: Χ”ΧΆΧ¨Χ›Χ Χ΅Χ™Χ›Χ•Χ ΧΧ©Χ¨ΧΧ™ Χ•Χ—Χ™Χ–Χ•Χ™ Χ”ΧΧ ΧΧ§Χ•Χ— Χ™Χ—Χ–Χ™Χ¨ Χ”ΧΧ•Χ•ΧΧ”
3. **Χ©Χ™Χ•Χ•Χ§**: Χ—Χ™Χ–Χ•Χ™ Χ”ΧΧ ΧΧ§Χ•Χ— Χ™Χ¨Χ›Χ•Χ© ΧΧ•Χ¦Χ¨ ΧΧ΅Χ•Χ™Χ
4. **Χ—Χ™Χ Χ•Χ**: Χ—Χ™Χ–Χ•Χ™ Χ”Χ¦ΧΧ—Χ” ΧΧ• Χ›Χ™Χ©ΧΧ•Χ Χ©Χ ΧΧΧΧ™Χ“Χ™Χ
5. **ΧΧ“ΧΆΧ™ Χ”Χ—Χ‘Χ¨Χ”**: Χ Χ™ΧΧ•Χ— Χ©Χ Χ”Χ—ΧΧΧ•Χ Χ‘Χ™Χ ΧΧ¨Χ™Χ•Χ
  
## ΧΧ¨Χ’Χ™Χ Χ Χ•Χ΅Χ£
  
**ΧΧ¨Χ’Χ™Χ**: 
Χ—Χ‘Χ¨Χ ΧΧ©Χ¨ΧΧ™ Χ¨Χ•Χ¦Χ” ΧΧ—Χ–Χ•Χ Χ”ΧΧ ΧΧ§Χ•Χ— Χ™Χ—Χ–Χ™Χ¨ ΧΧ Χ”Χ”ΧΧ•Χ•ΧΧ” Χ©ΧΧ• (1=Χ”Χ—Χ–Χ™Χ¨, 0=ΧΧ Χ”Χ—Χ–Χ™Χ¨) ΧΆΧ Χ΅ΧΧ Χ”Χ”Χ›Χ Χ΅Χ” Χ”Χ©Χ ΧΧ™Χ Χ©ΧΧ• (Χ‘ΧΧΧ¤Χ™ Χ©Χ§ΧΧ™Χ). ΧΧ”ΧΧ Χ ΧΧ•Χ Χ™Χ Χ”Χ™Χ΅ΧΧ•Χ¨Χ™Χ™Χ:
  
| Χ”Χ›Χ Χ΅Χ” Χ©Χ ΧΧ™Χ (ΧΧΧ¤Χ™ Χ©"Χ—) | Χ”Χ—Χ–Χ™Χ¨ Χ”ΧΧ•Χ•ΧΧ” (1=Χ›Χ, 0=ΧΧ) |
|------------------------|---------------------------|
| 30                     | 0                         |
| 35                     | 0                         |
| 40                     | 0                         |
| 45                     | 0                         |
| 50                     | 0                         |
| 55                     | 1                         |
| 60                     | 0                         |
| 65                     | 1                         |
| 70                     | 1                         |
| 75                     | 1                         |
| 80                     | 1                         |
| 85                     | 1                         |
| 90                     | 1                         |
  
1. Χ‘Χ Χ” ΧΧ•Χ“Χ Χ¨Χ’Χ¨Χ΅Χ™Χ” ΧΧ•Χ’Χ™Χ΅ΧΧ™Χ Χ©ΧΧΧΧ¨ ΧΧ Χ”Χ§Χ©Χ¨ Χ‘Χ™Χ Χ”Χ”Χ›Χ Χ΅Χ” Χ”Χ©Χ ΧΧ™Χ ΧΧ‘Χ™Χ Χ”Χ—Χ–Χ¨ Χ”Χ”ΧΧ•Χ•ΧΧ”.
2. ΧΧ” Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©ΧΧ§Χ•Χ— ΧΆΧ Χ”Χ›Χ Χ΅Χ” Χ©Χ ΧΧ™Χ Χ©Χ 58 ΧΧΧ£ Χ©"Χ— Χ™Χ—Χ–Χ™Χ¨ ΧΧ Χ”Χ”ΧΧ•Χ•ΧΧ”?
3. ΧΧ”Χ™ Χ”Χ”Χ›Χ Χ΅Χ” Χ”Χ©Χ ΧΧ™Χ Χ”ΧΧ™Χ Χ™ΧΧΧ™Χ Χ©ΧΧ§Χ•Χ— Χ¦Χ¨Χ™Χ Χ›Χ“Χ™ Χ©Χ”Χ”Χ΅ΧΧ‘Χ¨Χ•Χ Χ©Χ™Χ—Χ–Χ™Χ¨ ΧΧ Χ”Χ”ΧΧ•Χ•ΧΧ” ΧΧ”Χ™Χ” ΧΧ¤Χ—Χ•Χ 75%?
  