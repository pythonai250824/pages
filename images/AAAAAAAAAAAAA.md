### ğŸ§  ×”×ª×××” ××™×©×™×ª ×©×œ NER ×‘Ö¾spaCy

#### ×œ××” × ×¨×¦×” ×œ×”×•×¡×™×£ ×™×©×•×™×•×ª ×™×“× ×™×ª?
×œ×¤×¢××™× spaCy ×œ× ××–×”×” ×™×©×•×™×•×ª ×©×× ×—× ×• ×›×Ÿ ×¨×•×¦×™× ×œ×–×”×•×ª â€“ ×œ×“×•×’××”, "Tesla" ×œ× ××–×•×”×” ×›×‘×¨×™×¨×ª ××—×“×œ ×›×™×©×•×ª ××¡×•×’ ORG  
×‘××§×¨×™× ×›××œ×” × ×•×›×œ ×œ×”×•×¡×™×£ ××ª ×”×™×©×•×ª ×™×“× ×™×ª ×œ××¡××š

#### ×”×©×œ×‘×™× ×œ×”×•×¡×¤×ª ×™×©×•×ª ×™×“× ×™×ª:
1. ×©×œ×™×¤×ª ×”×¢×¨×š ×”××¡×¤×¨×™ (hash) ×©×œ ×”×ª×•×•×™×ª ×”×¨×¦×•×™×” (×œ××©×œ "ORG")
2. ×™×¦×™×¨×ª Span ××”××™×œ×” ××• ×”×‘×™×˜×•×™ ×”×¨×¦×•×™
3. ×”×•×¡×¤×ª ×”Ö¾Span ×œ×¨×©×™××ª ×”×™×©×•×™×•×ª ×‘××¡××š `doc.ents`

```python
from spacy.tokens import Span

ORG = doc.vocab.strings["ORG"]
new_ent = Span(doc, start=0, end=1, label=ORG)
doc.ents = list(doc.ents) + [new_ent]
```

#### ×“×•×’××” ××ª×§×“××ª â€“ Phrase Matcher
×× × ×¨×¦×” ×œ×–×”×•×ª ×‘×™×˜×•×™×™× ×©×œ××™× ×›××•:
- `dashboard website`
- `dashboard-website`

× ×©×ª××© ×‘Ö¾PhraseMatcher ×œ×–×™×”×•×™ ×”×‘×™×˜×•×™×™× ×‘××¡××š, ×•××– × ×•×¡×™×£ ××•×ª× ×›×™×©×•×™×•×ª:

```python
from spacy.matcher import PhraseMatcher

matcher = PhraseMatcher(nlp.vocab)
patterns = [nlp("dashboard website"), nlp("dashboard-website")]
matcher.add("PRODUCT", patterns)

matches = matcher(doc)
new_ents = [Span(doc, start, end, label=doc.vocab.strings["PRODUCT"]) for match_id, start, end in matches]
doc.ents = list(doc.ents) + new_ents
```

#### ×©×™××•×©×™× × ×•×¡×¤×™×:
××¤×©×¨ ×’×:
- ×œ×¡×¤×•×¨ ×™×©×•×™×•×ª ×œ×¤×™ ×¡×•×’: `len([ent for ent in doc.ents if ent.label_ == "ORG"])`
- ×œ×”×¦×™×’ ××ª ×›×œ ×”×™×©×•×™×•×ª ×¢× ×”×¡×•×’×™× ×©×œ×”×Ÿ
- ×œ×”×“×¤×™×¡ ××ª ××™×§×•× ×”×”×ª×—×œ×” ×•×”×¡×™×•× ×©×œ ×›×œ ×™×©×•×ª
