# Χ Χ™ΧΧ•Χ— ΧΧ§Χ΅Χ ΧΆΧ SpaCy β€“ Χ¤Χ•Χ Χ§Χ¦Χ™Χ•Χ ΧΧ™Χ•Χ Χ‘Χ΅Χ™Χ΅Χ™Χ Χ”ΧΧ©Χ

## Noun Chunks, displaCy, and Visualization in SpaCy

## π§  ΧΧ” Χ–Χ” Noun Chunk?

### Noun Chunk (Χ¦Χ™Χ¨Χ•Χ£ Χ©ΧΧ Χ™)

Χ”Χ©Χ•Χ¨Χ© Χ©ΦΎΧΦΎΧΆ ΧΧ• ΧΧ™ΧΧ¨ Χ“Χ™Χ•Χ§ ΧΧ”ΧΧ™ΧΧ” Χ©ΦµΧΧ β€” Χ‘ΧΧ©ΧΧΆΧ•Χ Χ©Χ ΧΆΧ¦Χ

Χ¦Χ™Χ¨Χ•Χ£ Χ©ΧΧ Χ™ Χ”Χ•Χ Χ¨Χ¦Χ£ ΧΧ™ΧΧ™Χ Χ©ΧΧ›Χ™Χ β­Χ©Χ ΧΆΧ¦Χβ­ (ΧΧ• Χ›Χ Χ•Χ™ Χ’Χ•Χ£) Χ™Χ—Χ“ ΧΆΧ ΧΧΧ¨Χ™Χ, ΧΧ™ΧΧ•Χ Χ™Χ—Χ΅ ΧΧ• Χ§Χ‘ΧΆΧ™Χ Χ©ΧΧΧΧ¨Χ™Χ ΧΧ•ΧΧ•.

#### Χ“Χ•Χ’ΧΧ:
> "The quick brown fox" β† Χ¦Χ¨Χ•Χ£ Χ©ΧΧ Χ™ ΧΧ—Χ“

## Χ›Χ™Χ¦Χ“ SpaCy ΧΧ–Χ”Χ” ΧΧ•ΧΧ?

Χ”ΧΧ•Χ“Χ ΧΧ–Χ”Χ” Χ‘ΧΧ•Χ¤Χ ΧΧ•ΧΧ•ΧΧΧ™ Χ¦Χ™Χ¨Χ•Χ¤Χ™Χ Χ©ΧΧ Χ™Χ™Χ Χ‘Χ›Χ ΧΧ©Χ¤Χ Χ‘ΧΧ§Χ΅Χ, Χ•ΧΧ¦Χ™ΧΆ ΧΧ”Χ Χ’Χ™Χ©Χ” ΧΆΧ `noun_chunks`

```python
import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp("The quick brown fox jumps over the lazy dog.")

for chunk in doc.noun_chunks:
    print(chunk.text)
```

#### Output:
```
The quick brown fox
the lazy dog
```

## ΧΧΧ” Χ–Χ” Χ©Χ™ΧΧ•Χ©?

Noun Chunks represent meaningful content units that reflect the main entities and owners in the sentence

Recognizing them helps identify the core structure and focus of the text

### Uses of Noun Chunks:
- **Information Retrieval** β†’ Isolate and extract relevant information from text  
- **Text Summarization** β†’ Identify the most informative parts of a sentence  
- **Semantic NLP Tasks** β†’ Useful in tasks involving deeper understanding of meaning and relationships in text

## Χ”- π¨ displaCy β€“ Χ•Χ™Χ–Χ•ΧΧΧ™Χ–Χ¦Χ™Χ” Χ’Χ¨Χ¤Χ™Χ

Χ΅Χ¤Χ™Χ™Χ΅Χ™ ΧΧ¦Χ™ΧΆΧ” ΧΧ displaCy Χ›Χ›ΧΧ™ Χ©ΧΧ–Χ”Χ” Χ‘Χ΅Χ‘Χ™Χ‘Χ Χ”Χ”Χ¤ΧΆΧΧ” ΧΧ Χ”ΧΧ‘Χ Χ” Χ”Χ’Χ¨ΧΧΧ™ Χ©Χ Χ”ΧΧ©Χ¤Χ Χ•ΧΧ Χ”Χ™Χ©Χ•Χ™Χ•Χ Χ‘Χ©Χ  
Χ”ΧΧ•Χ Χ— "ΧΧ‘Χ Χ” Χ“Χ§Χ“Χ•Χ§Χ™" (ΧΧ•: ΧΧ‘Χ Χ” Χ’Χ¨ΧΧΧ™Χ§ΧΧ™) Χ‘ΧΧ©Χ¤Χ ΧΧΧΧ¨ ΧΧ Χ”ΧΧ•Χ¤Χ Χ©Χ‘Χ• Χ”ΧΧ™ΧΧ™Χ ΧΧ§Χ•Χ©Χ¨Χ•Χ Χ–Χ• ΧΧ–Χ• ΧΧ‘Χ—Χ™Χ Χ” ΧΧ—Χ‘Χ™Χ¨Χ™Χ β€“ Χ›ΧΧ•ΧΧ¨, ΧΧ™ Χ”Χ Χ•Χ©Χ, ΧΧ”Χ• Χ”Χ¤Χ•ΧΆΧ, ΧΧ™ Χ”ΧΧ•Χ©Χ, ΧΧ™Χ ΧΧ™ΧΧ Χ™Χ—Χ΅ ΧΧΧ—Χ‘Χ¨Χ ΧΧ©ΧΧ¨ Χ”ΧΧ©Χ¤Χ, Χ•ΧΆΧ•Χ“

### Χ©Χ™Χ Χ•Χ™ displaCy:
- **Dependency Parsing** β†’ ΧΧ¦Χ™Χ’ ΧΧ Χ”Χ§Χ©Χ¨ Χ‘Χ™Χ Χ”ΧΧ™ΧΧ™Χ
- **Named Entity Recognition (NER)** β†’ ΧΧ¦Χ™Χ’ ΧΧ Χ”Χ™Χ©Χ•Χ™Χ•Χ Χ”Χ©Χ

### ΧΧ“Χ•Χ’ΧΧ:
```python
from spacy import displacy
import spacy

nlp = spacy.load("en_core_web_sm")
doc = nlp("Apple is looking to buy a startup in Hong Kong for $6 million")

displacy.render(doc, style="dep", jupyter=True)  # ΧΧ”Χ¦Χ™Χ’ ΧΧ—Χ‘Χ™Χ¨

displacy.render(doc, style="ent", jupyter=True)  # ΧΧ”Χ¦Χ™Χ’ Χ™Χ©Χ•Χ™Χ•Χ Χ‘Χ©Χ
```

<img src="nlp14.png" style="width: 100%" />

<img src="nlp16.png" style="width: 60%" />

```python
doc = nlp('Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')
displacy.render(doc, style='ent', jupyter=True)
```

<img src="nlp15.png" style="width: 75%" />

### Χ΅Χ™Χ›Χ•Χ:

* `noun_chunks` returns noun phrases automatically from the text
* `displaCy` offers visual representation of key linguistic elements in the sentence
* Understanding and using these tools helps you analyze both the structure and content of text effectively

## Χ”- Stemming β€“ ΧΧ” Χ–Χ” Χ•ΧΧΧ” Χ–Χ” Χ—Χ©Χ•Χ‘

Χ”- Stemming Χ”Χ™Χ ΧΧ›Χ Χ™Χ§Χ Χ§Χ“Χ-ΧΆΧ™Χ‘Χ•Χ“ Χ‘ΧΧ—Χ•Χ ΧΆΧ™Χ‘Χ•Χ“ Χ©Χ¤Χ” ΧΧ‘ΧΆΧ™Χ (NLP)

Χ”ΧΧΧ¨Χ” Χ©Χ stemming Χ”Χ™Χ ΧΧ”Χ—Χ–Χ™Χ¨ ΧΧ™ΧΧ™Χ ΧΧ¦Χ•Χ¨Χ Χ”Χ©Χ•Χ¨Χ© Χ©ΧΧ”Χ Χ›Χ“Χ™ Χ©ΧΧ™ΧΧ™Χ ΧΆΧ ΧΧ•ΧΧ” ΧΧ©ΧΧΆΧ•Χ Χ‘Χ΅Χ™Χ΅Χ™Χ Χ™Χ™Χ—Χ©Χ‘Χ• ΧΧ©Χ•Χ•Χ

ΧΧ“Χ•Χ’ΧΧ”:

* "running", "runner", "ran" β†’ Χ›Χ•ΧΧ ΧΧ—Χ–Χ™Χ¨Χ™Χ ΧΧ Χ”Χ©Χ•Χ¨Χ©: "run"
* "fairness", "fairly" β†’ ΧΧ©ΧΧ™Χ”Χ Χ”Χ©Χ•Χ¨Χ©: "fair"

### ΧΧΧ” ΧΧ”Χ©ΧΧΧ© Χ‘ΦΎStemming

* ΧΧ§ΧΧ™Χ Χ•Χ¨Χ™ΧΧ¦Χ™Χ•Χ Χ©Χ ΧΧ™ΧΧ™Χ ΧΧ¦Χ•Χ¨Χ” Χ‘Χ΅Χ™Χ΅Χ™Χ ΧΧ—Χ
* ΧΧ•Χ¨Χ ΧΧ”ΧΧΧΧ” ΧΧ•Χ‘Χ” Χ™Χ•ΧΧ¨ Χ‘Χ™Χ ΧΧ΅ΧΧ›Χ™Χ Χ•Χ©ΧΧ™ΧΧΧ•Χ Χ‘Χ—Χ™Χ¤Χ•Χ© ΧΧ™Χ“ΧΆ
* ΧΧ§ΧΧ™Χ ΧΧ ΧΧ΅Χ¤Χ¨ Χ”ΧΧ™ΧΧ™Χ Χ”Χ™Χ™Χ—Χ•Χ“Χ™Χ•Χ Χ‘ΧΧ§Χ΅Χ

### ΧΧΧ’Χ•Χ¨Χ™ΧΧΧ™Χ Χ Χ¤Χ•Χ¦Χ™Χ

* **Porter Stemmer** β€“ Χ Χ¤Χ•Χ¥ ΧΧΧ•Χ“ Χ‘ΧΧ Χ’ΧΧ™Χ, ΧΧ©ΧΧΧ© Χ‘Χ—Χ•Χ§Χ™Χ Χ§Χ‘Χ•ΧΆΧ™Χ ΧΧ§Χ™Χ¦Χ•Χ¥ Χ΅Χ™Χ•ΧΧ•Χ
* **Snowball Stemmer** β€“ Χ’Χ¨Χ΅Χ” ΧΧΧ§Χ“ΧΧ Χ™Χ•ΧΧ¨ Χ©Χ Χ¤Χ•Χ¨ΧΧ¨, ΧΧ•ΧΧ›Χ Χ‘ΧΧ΅Χ¤Χ¨ Χ©Χ¤Χ•Χ

### Χ©Χ™ΧΧ• ΧΧ‘

Χ”- spaCy ΧΧ Χ›Χ•ΧΧΧ stemmer ΧΧ•Χ‘Χ Χ”
Χ›Χ“Χ™ ΧΧ”Χ©ΧΧΧ© Χ‘ΦΎstemming, Χ¦Χ¨Χ™Χ ΧΧ™Χ™Χ‘Χ ΧΧ•ΧΧ• ΧΧ΅Χ¤Χ¨Χ™Χ™Χ” Χ—Χ™Χ¦Χ•Χ Χ™Χ Χ›ΧΧ• NLTK

```python
pip install nltk
```

<img src="nlp17.png" style="width: 100%" />

### Χ“Χ•Χ’ΧΧ” Χ‘Χ§Χ•Χ“

```python
import nltk
from nltk.stem import PorterStemmer, SnowballStemmer

stemmer = PorterStemmer()
words = ['run','runner','running','ran','runs','easily','fairly','fairness']
for word in words:
    print(word, "β†’", stemmer.stem(word))
```

Output:

```
run β†’ run
runner β†’ runner
running β†’ run
ran β†’ ran
runs β†’ run
easily β†’ easili
fairly β†’ fairli  # wrong ΧΧ ΧΧ™ΧΧ” ΧΧ§Χ Χ™Χ Χ‘ΧΧ Χ’ΧΧ™Χ
fairness β†’ fair
```

### Χ“Χ•Χ’ΧΧ” ΧΆΧ Snowball

```python
import nltk
from nltk.stem import PorterStemmer, SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

words = ['run','runner','running','ran','runs','easily','fairly','fairness']

for word in words:
    print(word+' --> '+s_stemmer.stem(word))
```

Output:
```
run --> run
runner --> runner
running --> run
ran --> ran
runs --> run
easily --> easili # wrong
fairly --> fair  # correct 
fairness --> fair
```

Χ”- Snowball Χ”Χ—Χ–Χ™Χ¨ "fair" Χ•ΧΧ "fairli" Χ›ΧΧ• Χ”ΧΧΧ’Χ•Χ¨Χ™ΧΧ Χ©Χ Porter

Χ”Χ΅Χ™Χ‘Χ” Χ©Χ”ΦΎPorter Stemmer ΧΧ—Χ–Χ™Χ¨ `fairli` Χ•Χ”ΦΎSnowball Stemmer ΧΧ—Χ–Χ™Χ¨ `fair` Χ Χ•Χ‘ΧΆΧ ΧΧ”Χ©Χ•Χ Χ™ Χ‘Χ—Χ•Χ§Χ™Χ Χ©Χ Χ©Χ Χ™ Χ”ΧΧΧ’Χ•Χ¨Χ™ΧΧΧ™Χ:

#### ΧΧΧ” Porter ΧΧ—Χ–Χ™Χ¨ `fairli`

Χ”- Porter Stemmer Χ¤Χ©Χ•Χ ΧΧ§Χ¦Χ¨ Χ΅Χ™Χ•ΧΧ•Χ ΧΧ¤Χ™ Χ›ΧΧΧ™Χ Χ§Χ‘Χ•ΧΆΧ™Χ Χ‘ΧΧ™ ΧΧ”Χ‘Χ™Χ ΧΧ ΧΧ©ΧΧΆΧ•Χ Χ”ΧΧ™ΧΧ”
Χ‘ΧΧ§Χ¨Χ” Χ©Χ `fairly`, Χ”Χ•Χ ΧΧ•Χ¨Χ™Χ“ Χ¨Χ§ ΧΧ `-ly` ΧΧ‘Χ ΧΧ ΧΧΧ©Χ™Χ Χ”ΧΧΧ” Χ•ΧΧ›Χ Χ Χ©ΧΧ¨ ΧΆΧ `fairli` β€“ Χ©Χ”Χ•Χ ΧΧ Χ‘ΧΧΧ ΧΧ™ΧΧ” Χ Χ›Χ•Χ Χ”

#### ΧΧΧ” Snowball ΧΧ—Χ–Χ™Χ¨ `fair`

Χ”- Snowball Stemmer Χ”Χ•Χ Χ’Χ¨Χ΅Χ” Χ—Χ›ΧΧ” Χ™Χ•ΧΧ¨
Χ”Χ•Χ ΧΧ•Χ§Χ— Χ‘Χ—Χ©Χ‘Χ•Χ Χ”Χ§Χ©Χ¨ ΧΧ©Χ•Χ Χ™ Χ¨Χ—Χ‘ Χ™Χ•ΧΧ¨ 

Χ•ΧΧ›Χ™Χ Χ—Χ•Χ§Χ™Χ ΧΧ•Χ¨Χ—Χ‘Χ™Χ Χ©ΧΧ–Χ”Χ™Χ Χ’Χ Χ§Χ•Χ Χ΅ΧΧ¨Χ•Χ§Χ¦Χ™Χ•Χ Χ Χ¤Χ•Χ¦Χ•Χ Χ›ΧΧ• `-ly`

ΧΧ›Χ Χ”Χ•Χ Χ™Χ•Χ“ΧΆ ΧΧ—ΧΧ•Χ ΧΧ Χ”Χ΅Χ™Χ•ΧΧ Χ Χ›Χ•Χ Χ•ΧΧ”Χ—Χ–Χ™Χ¨ ΧΧ Χ”Χ©Χ•Χ¨Χ© `fair` Χ©Χ”Χ•Χ Χ‘ΧΧΧ ΧΧ•Χ‘Χ Χ•Χ©Χ™ΧΧ•Χ©Χ™

#### ΧΧΧ” Snowball ΧΧ—Χ–Χ™Χ¨ `easili` Χ•ΧΧ `easy`

Χ’Χ Snowball, ΧΧΧ¨Χ•Χ Χ©Χ”Χ•Χ Χ—Χ›Χ Χ™Χ•ΧΧ¨ ΧΦΎPorter, ΧΆΧ“Χ™Χ™Χ ΧΧ‘Χ•Χ΅Χ΅ ΧΆΧ Χ›ΧΧΧ™Χ Χ•ΧΧ ΧΧ‘Χ™Χ ΧΧ Χ”ΧΧ©ΧΧΆΧ•Χ Χ”ΧΧΧΧ” Χ©Χ Χ”ΧΧ™ΧΧ”
Χ”Χ•Χ ΧΧ–Χ”Χ” Χ©Χ΅Χ™Χ•Χ `-ly` Χ Χ¤Χ•Χ¥ Χ•ΧΧ›Χ Χ—Χ•ΧΧ ΧΧ•ΧΧ•
ΧΧ‘Χ ΧΧ—Χ¨Χ™ Χ”Χ—Χ™ΧΧ•Χ Χ”Χ•Χ ΧΧ ΧΧ¦ΧΧ™Χ— ΧΧ”Χ—Χ–Χ™Χ¨ ΧΧ Χ”Χ¦Χ•Χ¨Χ” Χ”ΧΧ§Χ Χ™Χ `easy` ΧΧΧ ΧΆΧ•Χ¦Χ¨ Χ‘ΦΎ`easili`, Χ›Χ™:

* Χ”ΧΧΧ’Χ•Χ¨Χ™ΧΧ ΧΧ ΧΧ‘Χ¦ΧΆ ΧΧ™Χ§Χ•Χ ΧΧ•Χ¨ΧΧ•Χ’Χ¨Χ¤Χ™ (spelling correction)
* ΧΧ™Χ ΧΧ• Χ’Χ™Χ©Χ” ΧΧΧ™ΧΧ•Χ ΧΧ• Χ›ΧΧ™Χ ΧΧ”Χ‘Χ™Χ Χ©ΧΧ“Χ•Χ‘Χ¨ Χ‘Χ©Χ•Χ¨Χ© `easy`

#### Χ”ΧΧ `easili` Χ”Χ™Χ ΧΧΆΧ•Χ

Χ›Χ β€” ΧΧ‘Χ—Χ™Χ Χ ΧΧ Χ’ΧΧ™Χ ΧΧ§Χ Χ™Χ, `easili` ΧΧ™Χ Χ” ΧΧ™ΧΧ” Χ§Χ™Χ™ΧΧ
Snowball ΧΆΧ©Χ” Χ—Χ™ΧΧ•Χ Χ Χ›Χ•Χ Χ—ΧΧ§Χ™Χ, ΧΧ‘Χ ΧΧ ΧΧ•Χ©ΧΧ

#### ΧΧ” Χ”Χ¤ΧΧ¨Χ•Χ

ΧΧ Χ—Χ©Χ•Χ‘ ΧΧ ΧΧ§Χ‘Χ ΧΧ™ΧΧ™Χ ΧΧ§Χ Χ™Χ•Χ ΧΧΧ™ΧΧ™Χ•Χ, Χ›Χ“ΧΧ™ ΧΧ”Χ©ΧΧΧ© Χ‘ΦΎLemmatization Χ‘ΧΧ§Χ•Χ Stemming
Lemmatization ΧΧ©ΧΧΧ©Χ Χ‘Χ“Χ§Χ“Χ•Χ§ Χ•ΧΧ™ΧΧ•Χ Χ›Χ“Χ™ ΧΧ”Χ—Χ–Χ™Χ¨ Χ¦Χ•Χ¨Χ” Χ Χ›Χ•Χ Χ” Χ›ΧΧ• `easy`


### Χ΅Χ™Χ›Χ•Χ

Χ”- Stemming Χ”Χ•Χ Χ›ΧΧ™ Χ¤Χ©Χ•Χ ΧΧ Χ—Χ©Χ•Χ‘ Χ‘Χ”Χ›Χ Χ ΧΧ§Χ΅Χ ΧΧ Χ™ΧΧ•Χ—
Χ‘ΧΧ§Χ•Χ ΧΧΆΧ‘Χ•Χ“ ΧΆΧ Χ›Χ ΧΧ™ΧΧ” Χ›ΧΧ• Χ©Χ”Χ™Χ, ΧΧ Χ—Χ Χ• ΧΧ¦ΧΧ¦ΧΧ™Χ ΧΧ Χ›Χ•ΧΧ ΧΧ¦Χ•Χ¨Χ” ΧΧ—Χ™Χ“Χ” Χ›Χ“Χ™ ΧΧ”Χ‘Χ™Χ ΧΧ Χ”ΧΧ©ΧΧΆΧ•Χ Χ”ΧΧ¨Χ›Χ–Χ™Χ
